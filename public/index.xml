<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>PLAY Project on PLAY Project</title>
    <link>/</link>
    <description>Recent content in PLAY Project on PLAY Project</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title></title>
      <link>/study/protocol/recruiting/</link>
      <pubDate>Sun, 30 Dec 2018 00:00:00 -0500</pubDate>
      
      <guid>/study/protocol/recruiting/</guid>
      <description>

&lt;h1 id=&#34;inclusion-exclusion-criteria&#34;&gt;Inclusion/Exclusion Criteria&lt;/h1&gt;

&lt;p&gt;Infants&amp;rsquo; natural play in the home is characterized by tremendous variability including variations in: geographic location, climate, socioeconomic status (SES), maternal/paternal employment, childcare experiences, infants’ and mothers’ ages, language environment, physical layout and characteristics of the home, availability of media, toys for play, and so on.
Researchers will be able to explore the effects of any/all such factors.&lt;/p&gt;

&lt;p&gt;However, to ensure a sufficient sample size and based on conversations with the launch group, we will limit variability along several dimensions. To be included in the PLAY sample of 900 sessions, families must be two-parent households.
All infants must be English or Spanish monolingual or bilingual.
All infants must be the firstborn child and 12, 18, or 24 months of age (plus/minus one week). All infants must be full-term (37-40 weeks) without known disabilities.
The mother must act as the caregiver during visits, which will be scheduled at a time when only the mother and infant are present in the home.&lt;/p&gt;

&lt;h1 id=&#34;scheduling-visit&#34;&gt;Scheduling Visit&lt;/h1&gt;

&lt;h2 id=&#34;initial-recruiting-call&#34;&gt;Initial recruiting call&lt;/h2&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/0,79273/asset/64898/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/0,79273/asset/64898/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/0,79273/asset/64898/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Hi, may I speak with [MOM]?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;My name is [CALLER NAME] and I’m calling from [LAB]. We have a study for [12 / 18 / 24]-month-olds and [CHILD] is the perfect age. Can I tell you about it?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;What language(s) do you speak to [CHILD]?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;→ If not ENGLISH or SPANISH: end call&lt;/p&gt;

&lt;p&gt;&lt;em&gt;To control for differences in communication, we are looking for families who speak mainly English or Spanish. Would it be alright if you are contacted for other studies in the future?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;→ If yes: continue&lt;/p&gt;

&lt;p&gt;&lt;em&gt;For this study, we are interested in learning about babies’ natural, everyday experiences in their homes–such as the toys they play with and places they go.&lt;/em&gt;
&lt;em&gt;For this study, a researcher will visit you and [CHILD] in your home.&lt;/em&gt;
&lt;em&gt;You and [CHILD] will be video recorded for 1 hour as you go about your day.&lt;/em&gt;
&lt;em&gt;At the end of the visit we will ask questions about your family, your home, and [CHILD]’s skills and routines. We will also ask you to take us through your home as we do a video tour capturing the places [CHILD] gets to be throughout the day and things that [he/she] plays with.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The study will take about 2 hours. You will receive XXX for your participation.&lt;/em&gt;
&lt;em&gt;We will schedule a day and time that’s convenient for you and when [CHILD] is usually awake/alert and not during a typical meal time.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The data collected in this study are valuable and will be placed in a secure web-based library available only to researchers.&lt;/em&gt;
&lt;em&gt;The purpose is to share the data with experts in the field so that scientists can learn more about infant development.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Are you interested in participating?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;→ If yes:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Is there a day and time that works best for you (when [CHILD] is awake/alert and not a typical meal time)?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;→ If no:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Ok thank you. May we call you for other studies?&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;voicemail&#34;&gt;Voicemail&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Hi, this message is for [MOM]. My name is [NAME] and I’m calling from [LAB].&lt;/em&gt;
&lt;em&gt;I’m calling because we have a fun study for [12 / 18 / 24]-month-olds and [CHILD] is the perfect age.&lt;/em&gt;
&lt;em&gt;If you are interested in hearing more about the study, please give us a call back.&lt;/em&gt;
&lt;em&gt;Our phone number is [XXX-XXX-XXXX]. Thank you and we hope to hear from you soon!&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;confirming-the-visit-2-days-before-actual-visit-email-the-day-before&#34;&gt;Confirming the visit (2 days before actual visit, email the day before)&lt;/h2&gt;

&lt;p&gt;12-mo crawler
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14574/-/asset/61425/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14574/-/asset/61425/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14574/-/asset/61425/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;12-mo walker
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14167/-/asset/59866/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14167/-/asset/59866/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14167/-/asset/59866/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;18-mo
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14513/-/asset/61070/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14513/-/asset/61070/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14513/-/asset/61070/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;24-mo
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14514/-/asset/61427/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14514/-/asset/61427/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14514/-/asset/61427/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Hi, may I speak with [MOM]?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;My name is [NAME] and I’m calling from [LAB] to confirm our visit on [DATE].&lt;/em&gt;
&lt;em&gt;Before the visit, I’d like to ask you a few questions.&lt;/em&gt;
&lt;em&gt;It will only take 5 minutes of your time. Can we speak now?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;→ If yes:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Just as a reminder, the data we collect from you now and during the visit, will be shared on a web-based library only available to researchers like the professor who runs this lab.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;List of questions on the &lt;a href=&#34;phone_questionnaire.html&#34; target=&#34;_blank&#34;&gt;Phone Questionnaire&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Please note that presentation and format will differ in the app.&lt;/p&gt;

&lt;p&gt;→ If no:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Can I call you back today or tomorrow [before the visit]?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Schedule call.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/study/protocol/visit/</link>
      <pubDate>Sun, 30 Dec 2018 00:00:00 -0500</pubDate>
      
      <guid>/study/protocol/visit/</guid>
      <description>

&lt;h1 id=&#34;home-visit&#34;&gt;Home Visit&lt;/h1&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Say to Mom:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thanks for letting us come to your home. The visit has a few parts:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I’ll begin by video-recording you and [CHILD] as you go about your day. I will video-record you both for 1 hour. Then, I will ask [CHILD] to play with some toys both by him/herself and with you.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Afterwards, I will ask you some general questions about your family and home, and about [CHILD]’s skills and routines.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You will give me a tour of your home that I will record on video to get a sense of the places [CHILD] goes and things that he/she plays with.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Do you have any questions? Let’s start with reading and signing the consent.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;consent-to-participate-and-permission-to-share&#34;&gt;Consent to Participate and Permission to Share&lt;/h2&gt;

&lt;p&gt;Ask parent to review form asking for consent to participate in the study. When finished, give parent a moment to look over form and sign it.&lt;/p&gt;

&lt;p&gt;Ask parent to review form asking for permission to share videos and metadata.
When finished, give parent a moment to look over the form and sign it.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.databrary.org/resources/templates/release-template.html&#34; target=&#34;_blank&#34;&gt;Here&lt;/a&gt; is the Databrary Release Language.
&lt;a href=&#34;https://www.databrary.org/resources/guide/investigators/release/asking/examples.html&#34; target=&#34;_blank&#34;&gt;Here&lt;/a&gt; are videos depicting how to ask for permission to share and a sample script.&lt;/p&gt;

&lt;h2 id=&#34;visit-protocol&#34;&gt;Visit Protocol&lt;/h2&gt;

&lt;h3 id=&#34;1-1-hour-natural-play-video-shoes-noise-measurement&#34;&gt;1: 1-Hour Natural Play Video, Shoes, &amp;amp; Noise Measurement&lt;/h3&gt;

&lt;h4 id=&#34;12-mo-crawler-and-walker&#34;&gt;12-mo (crawler and walker)&lt;/h4&gt;

&lt;p&gt;Crawler participant view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14574/-/asset/61390/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14574/-/asset/61390/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14574/-/asset/61390/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Crawler experimenter view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14574/-/asset/61397/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14574/-/asset/61397/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14574/-/asset/61397/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Walker participant view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14167/-/asset/59930/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14167/-/asset/59930/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14167/-/asset/59930/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Walker experimenter view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14167/-/asset/59941/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14167/-/asset/59941/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14167/-/asset/59941/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;18-mo&#34;&gt;18-mo&lt;/h4&gt;

&lt;p&gt;Participant view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14513/-/asset/61218/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14513/-/asset/61218/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14513/-/asset/61218/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Experimenter view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14513/-/asset/61220/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14513/-/asset/61220/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14513/-/asset/61220/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;24-mo&#34;&gt;24-mo&lt;/h4&gt;

&lt;p&gt;Participant view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14514/-/asset/61054/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14514/-/asset/61054/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14514/-/asset/61054/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Experimenter view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14514/-/asset/61086/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14514/-/asset/61086/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14514/-/asset/61086/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Instruction to mom:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;For the next hour, do anything you would typically do if I weren’t here. Try to ignore me as much as possible and I will stay out of the way. I will also try not to respond to you and [CHILD] so that he/she is not distracted. You can go anywhere in your home. You can play together or not. The idea is to capture what your typical day is like.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Procedure:&lt;/p&gt;

&lt;p&gt;Keep camera on the child at all times.
Specifically, ensure that the child’s whole body is visible on camera. If mom is in frame, capture as much of her body as possible without compromising view of the child.
Record in front or to the side of the child as much as possible.
Do not zoom in.
Remain at as far a distance as possible (~3 to 5 m, hugging the wall) so that the child is not distracted by your presence.
Try not to interact with the child or make eye contact with the child. Just watch through the view finder of the camera.&lt;/p&gt;

&lt;h4 id=&#34;shoes&#34;&gt;Shoes&lt;/h4&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/0,6640/asset/65148/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/0,6640/asset/65148/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/0,6640/asset/65148/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If child is wearing shoes, video-record the shoes after the session; take them off child and video the bottom, side, and top views.&lt;/p&gt;

&lt;p&gt;Procedure:&lt;/p&gt;

&lt;p&gt;Zoom in with camera and comment on shoe type, heel (if any), and other observations.&lt;/p&gt;

&lt;h4 id=&#34;decibel-meter&#34;&gt;Decibel Meter&lt;/h4&gt;

&lt;p&gt;Open the app on your tablet and start running it just before you begin recording the free play video portion of the visit.&lt;/p&gt;

&lt;p&gt;Procedure:&lt;/p&gt;

&lt;p&gt;Open application (the application immediately starts recording noise levels upon startup).
Place device in the most central place in the home (e.g., living room)&lt;/p&gt;

&lt;h3 id=&#34;2-solitary-play&#34;&gt;2: Solitary Play&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63732/download?inline=true&#34;/&gt;&lt;/p&gt;

&lt;h4 id=&#34;12-mo-crawler-walker&#34;&gt;12-mo crawler &amp;amp; walker&lt;/h4&gt;

&lt;p&gt;12-mo crawler participant view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14574/-/asset/61352/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14574/-/asset/61352/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14574/-/asset/61352/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;12-mo crawler experimenter view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14574/-/asset/61358/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14574/-/asset/61358/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14574/-/asset/61358/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;12-mo walker participant view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14167/-/asset/59918/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14167/-/asset/59918/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14167/-/asset/59918/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;12-mo walker experimenter view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14167/-/asset/59928/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14167/-/asset/59928/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14167/-/asset/59928/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;18-mo-1&#34;&gt;18-mo&lt;/h4&gt;

&lt;p&gt;18-mo participant view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14513/-/asset/61064/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14513/-/asset/61064/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14513/-/asset/61064/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;18-mo experimenter view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14513/-/asset/61078/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14513/-/asset/61078/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14513/-/asset/61078/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;24-mo-1&#34;&gt;24-mo&lt;/h4&gt;

&lt;p&gt;24-mo participant view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14514/-/asset/61052/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14514/-/asset/61052/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14514/-/asset/61052/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;24-mo experimenter view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14514/-/asset/61060/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14514/-/asset/61060/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14514/-/asset/61060/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Interviewer:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;For the next few minutes, we want to see how [CHILD] plays by him/herself. We ask you not to distract him/her or tell him/her how to play. If [CHILD] tries to get your attention or wants to play with you, you can say, “Go play. It’s perfectly fine if he/she doesn’t play with the toy. Say to child: Here [CHILD], play with this!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Camera:&lt;/p&gt;

&lt;p&gt;Record solitary toy play so that view is on baby’s body entirely and hands on object.
If child moves around, follow child and keep face in frontal view.
Procedure:
Set yoga mat down on the floor. Un-stack cups and arrange randomly, standing upright (out of child’s view).
Place child in a sitting position on yoga mat and start timing after you present the toy.
Use timer on the camera (let the timer run for a bit longer than 2 min to avoid cutting the play time short. Later we code only 2 min of engagement).
After 2 minutes, say: &lt;em&gt;“Great job!”&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-dyadic-mother-child-play&#34;&gt;3: Dyadic (Mother-Child) Play&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63731/download?inline=true&#34;/&gt;&lt;/p&gt;

&lt;h4 id=&#34;12-mo-crawler-walker-1&#34;&gt;12-mo crawler &amp;amp; walker&lt;/h4&gt;

&lt;p&gt;[VIDEO 12-mo crawler participant view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14574/-/asset/61354/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14574/-/asset/61354/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14574/-/asset/61354/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;12-mo crawler experimenter view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14574/-/asset/61358/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14574/-/asset/61358/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14574/-/asset/61358/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;12-mo walker participant view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14167/-/asset/59920/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14167/-/asset/59920/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14167/-/asset/59920/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;12-mo walker experimenter view starts at 03:40
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14167/-/asset/59928/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14167/-/asset/59928/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14167/-/asset/59928/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;18-mo-2&#34;&gt;18-mo&lt;/h4&gt;

&lt;p&gt;18-mo participant view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14513/-/asset/61066/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14513/-/asset/61066/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14513/-/asset/61066/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;18-mo experimenter view starts at 3:48
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14513/-/asset/61078/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14513/-/asset/61078/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14513/-/asset/61078/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;24-mo-2&#34;&gt;24-mo&lt;/h4&gt;

&lt;p&gt;24-mo participant view
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14514/-/asset/61050/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14514/-/asset/61050/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14514/-/asset/61050/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;24-mo experimenter view starts at 03:32
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14514/-/asset/61060/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14514/-/asset/61060/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14514/-/asset/61060/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Instructions:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Please sit next to [CHILD]. I’ll give you a toy. Please play with [CHILD].&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Procedure:&lt;/p&gt;

&lt;p&gt;Record so that the child and mother’s entire body and hands are captured.
Use timer on camera to time engagement.
After 3 minutes, say “Great job!”&lt;/p&gt;

&lt;h3 id=&#34;4-questionnaires-questionnaires-html&#34;&gt;4: &lt;a href=&#34;questionnaires.html&#34; target=&#34;_blank&#34;&gt;Questionnaires&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Please note that presentation and format will differ in the app.&lt;/p&gt;

&lt;h4 id=&#34;12-mo&#34;&gt;12-mo&lt;/h4&gt;

&lt;p&gt;12-mo crawler
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14514/-/asset/61050/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14514/-/asset/61050/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14514/-/asset/61050/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;12-mo walker
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14514/-/asset/61060/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14514/-/asset/61060/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14514/-/asset/61060/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;18-mo-3&#34;&gt;18-mo&lt;/h4&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14513/-/asset/61076/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14513/-/asset/61076/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14513/-/asset/61076/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;24-mo-3&#34;&gt;24-mo&lt;/h4&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14514/-/asset/61088/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14514/-/asset/61088/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14514/-/asset/61088/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;general-questionnaires&#34;&gt;General Questionnaires&lt;/h4&gt;

&lt;p&gt;Instructions:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I have some questions for you…&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;[Only give introduction to the sections that need introduction (i.e., ECBQ and MB-CDI)].&lt;/p&gt;

&lt;p&gt;A GoogleSheet with most of the questions in a database format can be found &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1pVOM2naRS_STCXx4nkaRDLO6_V5kGhFaduRfwsv7cnI/edit?usp=sharing&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Procedure:&lt;/p&gt;

&lt;p&gt;Set up camera to record the questionnaires.
You&amp;rsquo;ll need to change the battery on the camera to ensure sufficient power.
Sit next to the mom so she is able to read along.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;toys_pets.html&#34; target=&#34;_blank&#34;&gt;Toys &amp;amp; Pets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;home.html&#34; target=&#34;_blank&#34;&gt;HOME&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;gender.html&#34; target=&#34;_blank&#34;&gt;Gender Socialization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;locomotor_milestones.html&#34; target=&#34;_blank&#34;&gt;Locomotor milestones&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;eclsb_health.html&#34; target=&#34;_blank&#34;&gt;ECLS-B Health&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;typical_day.html&#34; target=&#34;_blank&#34;&gt;Typical Day&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;media.html&#34; target=&#34;_blank&#34;&gt;Media time &amp;amp; use&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;macarthur-bates-communicative-development-inventory-mb-cdi&#34;&gt;MacArthur-Bates Communicative Development Inventory (MB-CDI)&lt;/h4&gt;

&lt;p&gt;MB-CDI should be administered in the primary language of the mom.
Specific instructions and procedure are included in the questionnaire.&lt;/p&gt;

&lt;h4 id=&#34;ecbq-ecbq-html&#34;&gt;&lt;a href=&#34;ecbq.html&#34; target=&#34;_blank&#34;&gt;ECBQ&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;Read instructions on questionnaire.
Give mom answer sheet with rating scale.&lt;/p&gt;

&lt;h3 id=&#34;5-house-walkthrough-room-measurements&#34;&gt;5: House Walkthrough &amp;amp; Room Measurements&lt;/h3&gt;

&lt;h4 id=&#34;video-house-walkthrough&#34;&gt;Video House Walkthrough&lt;/h4&gt;

&lt;h4 id=&#34;12-mo-1&#34;&gt;12-mo&lt;/h4&gt;

&lt;p&gt;Crawler
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14574/-/asset/61356/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14574/-/asset/61356/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14574/-/asset/61356/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Walker
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14167/-/asset/59922/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14167/-/asset/59922/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14167/-/asset/59922/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;18-mo-4&#34;&gt;18-mo&lt;/h4&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14513/-/asset/61068/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14513/-/asset/61068/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14513/-/asset/61068/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;24-mo-4&#34;&gt;24-mo&lt;/h4&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14514/-/asset/61048/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14514/-/asset/61048/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14514/-/asset/61048/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Instructions:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Now, we would like to see the space that [CHILD] gets to explore throughout the day. Please give me a tour of your home as I follow with a camera, and take measurements of the spaces.&lt;/em&gt;
&lt;em&gt;As we walk around, please mention the things that [CHILD] plays with in each room. Please show me where you keep his/her clothes to give us an idea of the kinds of things he/she wears.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Procedure (Video):&lt;/p&gt;

&lt;p&gt;Pause at the entrance of the room.&lt;/p&gt;

&lt;p&gt;Name the room by its function (e.g., “This is where [CHILD] sleeps”).
First, pan the camera SLOWLY from Left to Right.
Then, pan the camera to Floor, name the different types of surfaces in the space (hardwood, plush carpet, thin rug, linoleum, tile, etc.), and then pan to the Ceiling.
Hold the camera in one hand while you take measurements of the room.
Do NOT turn off the camera when walking to next room.
Walk SLOWLY.&lt;/p&gt;

&lt;h4 id=&#34;room-measurements-with-laser-distance-measurer&#34;&gt;Room Measurements with Laser Distance Measurer&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://dev1.ed-projects.nyu.edu/wikis/docuwiki/lib/exe/fetch.php/image011.png?w=300&amp;tok=74e992&#34;/&gt;&lt;/p&gt;

&lt;p&gt;Measure all rooms in the house.
Room = any space used by someone on a regular basis, including: bedrooms, kitchens, bathrooms, and basements.
Do not measure laundry rooms.
Rooms don’t have to have windows.
A room has to have a clear demarcation (e.g., a wall or an entry).
If the room has a short divider (e.g., when a kitchen and a living room are divided by a counter), count as one big room and measure accordingly.&lt;/p&gt;

&lt;p&gt;Procedure:&lt;/p&gt;

&lt;p&gt;Turn measure on by pressing ON/DIST button.
Make sure the laser is on.
Place the base of the laser flat on the wall.
Avoid moldings and door castings.
Measure wall to wall, lengthwise and widthwise.
If a room has an odd or asymmetrical shape (i.e., any shape other than a rectangle or a square), measure the largest rectangle or square area of the room.
Press ON/DIST again to take measurement.
Repeat the above for length and width.
Focus camera on laser measure and read measurements out loud.&lt;/p&gt;

&lt;h3 id=&#34;6-body-dimensions&#34;&gt;6: Body Dimensions&lt;/h3&gt;

&lt;p&gt;[TBD]&lt;/p&gt;

&lt;h3 id=&#34;7-visit-wrap-up&#34;&gt;7: Visit Wrap-up&lt;/h3&gt;

&lt;p&gt;Complete home measurement, housing checklist sections of the Home Questionnaire.
When you arrive back at the lab, wash all toys and equipment thoroughly.
Wipe down yoga mat.
Rinse nesting cups in bleach-water.
Do not submerge shape sorter in water (or it will stop making noise).&lt;/p&gt;

&lt;h3 id=&#34;8-visit-post-processing&#34;&gt;8: Visit post-processing&lt;/h3&gt;

&lt;p&gt;Export questionnaire data from tablet.
Upload videos, questionnaires, and house decibel data to Databrary.
These pages describe the PLAY study data collection protocol in full.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/study/protocol/visit_prep/</link>
      <pubDate>Sun, 30 Dec 2018 00:00:00 -0500</pubDate>
      
      <guid>/study/protocol/visit_prep/</guid>
      <description>

&lt;h1 id=&#34;preparing-for-visit&#34;&gt;Preparing for Visit&lt;/h1&gt;

&lt;h2 id=&#34;prepare-paperwork&#34;&gt;Prepare paperwork&lt;/h2&gt;

&lt;p&gt;Write Participant ID on all paperwork (consents and questionnaires).
Fill out locomotor milestone worksheet.&lt;/p&gt;

&lt;h2 id=&#34;pack-equipment&#34;&gt;Pack equipment&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Camera, SD card and extra battery&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Mic&lt;/li&gt;
&lt;li&gt;Laser Measure&lt;/li&gt;
&lt;li&gt;Solitary play toy&lt;/li&gt;
&lt;li&gt;Dyadic play toy&lt;/li&gt;
&lt;li&gt;Yoga mat&lt;/li&gt;
&lt;li&gt;Tablet with app for questionnaires (if mom speaks English and/or Spanish, bring both versions of MacArthur), study consent form, Databrary sharing release form, and decibel meter.&lt;/li&gt;
&lt;li&gt;Answer choice sheet with response scales&lt;/li&gt;
&lt;li&gt;Participant payment&lt;/li&gt;
&lt;li&gt;Paper copies of all questionnaires, MCDI, and consent and Databrary forms in case of tablet failure&lt;/li&gt;
&lt;li&gt;Tools for body dimensions (Height and Weight)- TBD&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Hello, Hugo</title>
      <link>/post/getting-started/</link>
      <pubDate>Thu, 27 Dec 2018 12:37:00 -0500</pubDate>
      
      <guid>/post/getting-started/</guid>
      <description>&lt;p&gt;Hi, all.&lt;/p&gt;

&lt;p&gt;We have a project website and blog using the &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;blogdown&lt;/code&gt;&lt;/a&gt; package for R, and the Hugo &lt;strong&gt;Academic&lt;/strong&gt; theme.
Let us know what you think.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/study/coding/coding_setup/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0400</pubDate>
      
      <guid>/study/coding/coding_setup/</guid>
      <description>

&lt;h1 id=&#34;coding-set-up&#34;&gt;Coding Set Up&lt;/h1&gt;

&lt;p&gt;This section describes how to transcribe &amp;amp; code the 1-hour natural play session.&lt;/p&gt;

&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;

&lt;p&gt;Download the &lt;a href=&#34;http://datavyu.org/download.html&#34; target=&#34;_blank&#34;&gt;development version of Datavyu&lt;/a&gt;.
Download the &lt;code&gt;PLAY_CodingTemplate.opf&lt;/code&gt; file from the &lt;a href=&#34;https://nyu.databrary.org/volume/254/slot/14924/-?asset=73892&#34; target=&#34;_blank&#34;&gt;PLAY Databrary Volume&lt;/a&gt;.
Name this file with the PLAY naming convention (e.g., PLAY_NYU001, … PLAY_NYU010, … PLAY_NYU030).
  - This template contains all of the primary variables that will be coded by each site: communication, gesture, object interaction, locomotion, and emotion.
Download Ruby scripts for each coding variable as needed from the &lt;a href=&#34;https://github.com/databrary/PLAY-Project-Datavyu-scripts&#34; target=&#34;_blank&#34;&gt;PLAY Github repository&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;get-to-know-datavyu&#34;&gt;Get to Know Datavyu&lt;/h2&gt;

&lt;p&gt;Familiarize yourself with Datavyu before you begin coding (resources on Datavyu.org, videos from past workshops, etc.).
Refer to the &lt;a href=&#34;http://www.datavyu.org/user-guide/index.html&#34; target=&#34;_blank&#34;&gt;Datavyu User Guide&lt;/a&gt;.
Take a look at our &lt;a href=&#34;http://www.datavyu.org/user-guide/best-practices.html&#34; target=&#34;_blank&#34;&gt;Best Practices for Coding Behavioral Data From Video&lt;/a&gt; on the Datavyu site.&lt;/p&gt;

&lt;h2 id=&#34;coding-in-passes&#34;&gt;Coding in Passes&lt;/h2&gt;

&lt;p&gt;The coding manual describes the &lt;a href=&#34;transcription.html&#34; target=&#34;_blank&#34;&gt;transcription &lt;/a&gt; process and codes for 5 content areas: &lt;a href=&#34;communication.html&#34; target=&#34;_blank&#34;&gt;communication&lt;/a&gt;, &lt;a href=&#34;gesture.html&#34; target=&#34;_blank&#34;&gt;gesture&lt;/a&gt;, &lt;a href=&#34;objects.html&#34; target=&#34;_blank&#34;&gt;object interaction&lt;/a&gt;, &lt;a href=&#34;locomotion.html&#34; target=&#34;_blank&#34;&gt;locomotion&lt;/a&gt;, and &lt;a href=&#34;emotion.html&#34; target=&#34;_blank&#34;&gt;emotion&lt;/a&gt;.
Each content area includes two passes: one pass for the infant and one pass for the mother. For gesture, the baby and mom are coded together in a single pass.
A pass entails scoring the relevant codes for 1-hour of video.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Please visit our GitHub Repository &amp;lt;https://github.com/databrary/PLAY-Project-Datavyu-scripts&amp;gt; for all of the scripts mentioned in this wiki.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;workflow-for-coding-communication-passes&#34;&gt;Workflow for Coding Communication Passes&lt;/h2&gt;

&lt;p&gt;After the file has been transcribed according to procedure in Transcription, run two additional scripts that will prepare new Communication columns for further coding.
Run &lt;code&gt;splitmombaby_transcribe.rb&lt;/code&gt;. This script pulls out mom and baby language from the transcribe column into two new columns: (1) momspeech and (2) babyvoc.
Each column is automatically populated with cells from the respectively tagged utterances from the transcribe column (e.g., the script ports all utterances coded as ‘m’ to the momspeech column and &amp;lsquo;b&amp;rsquo; to the babyvoc column).
Each new cell in momspeech and babyvoc is a point cell created at the onset of each cell from the transcription.
Run create_mombaby_utterancetype.rb.
This script also creates two new columns: (1) momutterancetype and (2) babyutterancetype. For each cell in momspeech and babyvoc, a new cell is created in momutterancetype and babyutterancetype, respectively.
The codes for these cells are blank, and the coder now scores mom and baby communication according to definitions in Communication Codes.&lt;/p&gt;

&lt;h2 id=&#34;workflow-for-coding-gesture-pass&#34;&gt;Workflow for Coding Gesture Pass&lt;/h2&gt;

&lt;p&gt;Score baby and mom gesture together in a single pass according to definitions in Gesture Codes.
After the gesture coding pass (for both mom and baby) has been done, run a script that will separate mom and baby gestures into two columns.
Run &lt;code&gt;Split-MomBabyGesture.rb&lt;/code&gt;. This script pulls out mom and baby gestures from the gesture column into two new columns: (1) babygesture and (2) momgesture. Each column is automatically populated with cells from the respectively tagged events from the gesture column (e.g., the script ports all gestures coded as ‘m’ to the momgesture column and &amp;lsquo;b&amp;rsquo; to the babygesture column). Each new cell in babygesture and momgesture is a point cell created at the onset of each cell in the gesture column.&lt;/p&gt;

&lt;h2 id=&#34;workflow-for-object-objects-html-locomotion-locomotion-html-and-emotion-emotion-html-passes&#34;&gt;Workflow for &lt;a href=&#34;objects.html&#34; target=&#34;_blank&#34;&gt;Object&lt;/a&gt;, &lt;a href=&#34;locomotion.html&#34; target=&#34;_blank&#34;&gt;Locomotion&lt;/a&gt;, and &lt;a href=&#34;emotion.html&#34; target=&#34;_blank&#34;&gt;Emotion&lt;/a&gt; Passes&lt;/h2&gt;

&lt;p&gt;Choose whether to code baby or mom first within each pass for object, locomotion, or emotion.
Score each pass according to definitions in Object Codes, Locomotion Codes, or Emotion Codes.
Workflow for Inter-Observer Reliability on Communication, Gesture, Object, Locomotion, and Emotion Passes
After the primary coder finishes a pass: babyutterancetype, momutterancetype, gesture (split into babygesture, momgesture), babyobject, momobject, babyloc, momloc, babyemotion, or momemotion run two scripts to set up the Datavyu spreadsheet for coding reliability.
First, run a script called &lt;code&gt;insert-RelBlocks.rb&lt;/code&gt;.
This script randomly generates 3, 5-minute chunks within the first, second, and third 20-minute sections of the 1-hour video of free play. By quasi-randomly inserting reliability blocks from areas of the primary coder’s pass, this will ensure that the reliability coder sees each portion of the video for each child’s session. Thus, the idiosyncrasies of each child, fluctuations over the 1-hour session, and drift in the coder are spread over the session.
Reliability on each coding pass is done on the same 3, 5-minute blocks for each pass.
The scripting window in Datavyu will prompt when everything has been successfully completed. You should now have a brand new column in your spreadsheet named reliability_blocks.
This script should only be run once so that reliability coding can be done within the same time frame for each coding domain for each session.
Now, run another script appropriate for the pass reliability needs to be coded on: &lt;code&gt;CreateReliability-BabyUtterancetype.rb&lt;/code&gt; or &lt;code&gt;CreateReliability-MomUtterancetype.rb&lt;/code&gt; or &lt;code&gt;CreateReliability-Gesture.rb&lt;/code&gt; or &lt;code&gt;CreateReliability-MomBaby-Loc.rb&lt;/code&gt; or &lt;code&gt;CreateReliability-MomBaby-Object.rb&lt;/code&gt; OR &lt;code&gt;CreateReliability-MomBaby-Emotion.rb&lt;/code&gt;
This script inserts new coding columns where your reliability coder will score the video while they are locked into the script-generated, 5-minute chunks in the reliability_blocks column.&lt;/p&gt;

&lt;h1 id=&#34;coding-id&#34;&gt;Coding ID&lt;/h1&gt;

&lt;p&gt;Datavyu ID Code for 1-Hour Natural Play&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Make sure you are currently logged in at Databrary to view embedded video examples in this wiki.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;id&#34;&gt;id&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;site&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;participant&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;testdate&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;birthdate&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;agegroup&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;sex&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;study&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;babylanguage1&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;babylanguage2&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;momlanguage2&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;momlanguage2&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;operational-definitions&#34;&gt;Operational Definitions&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;onset/offset&amp;gt;&lt;/code&gt;: Set every ID cell onset to 00:00:00:000 (hours : minutes : seconds : milliseconds).&lt;/p&gt;

&lt;p&gt;Set ID cell offset to the last frame in the 1-hour free play session.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;site&amp;gt;&lt;/code&gt;: Site refers to the data collection site: New York University, Rutgers Newark, CUNY Staten Island, Penn State, etc.&lt;/p&gt;

&lt;p&gt;Get the site from the metadata information collected on the app.&lt;/p&gt;

&lt;p&gt;Format is three letters all caps: NYU, RTG, CSI, PSU.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;participant&amp;gt;&lt;/code&gt;: Participant number refers to the infant&amp;rsquo;s participant number in the order that the data were collected.&lt;/p&gt;

&lt;p&gt;Participant numbers run consecutively from 001 within each site.&lt;/p&gt;

&lt;p&gt;Get the participant number from the metadata information collected on the app.&lt;/p&gt;

&lt;p&gt;Format for id number is three digits 001, 012, 021.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;testdate&amp;gt;&lt;/code&gt;: Test date is the day of the home visit.&lt;/p&gt;

&lt;p&gt;Get the test date from the metadata information collected on the app.&lt;/p&gt;

&lt;p&gt;Format for test date is YYYY-MM-DD.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;birthdate&amp;gt;&lt;/code&gt;: Birth date is the day the baby was born.&lt;/p&gt;

&lt;p&gt;Get the birth date from the metadata information collected on the app.&lt;/p&gt;

&lt;p&gt;Format for birth date is YYYY-MM-DD.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;agegroup&amp;gt;&lt;/code&gt;: Entered as 12, 18, or 24.&lt;/p&gt;

&lt;p&gt;Get the age group from the metadata information collected on the app.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;sex&amp;gt;&lt;/code&gt;: Refers to infant&amp;rsquo;s biological sex.&lt;/p&gt;

&lt;p&gt;Code &lt;code&gt;m&lt;/code&gt; = male/boy; &lt;code&gt;f&lt;/code&gt; = female/girl.&lt;/p&gt;

&lt;p&gt;Get the sex from the metadata information collected on the app.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;study&amp;gt;&lt;/code&gt;: Study name.&lt;/p&gt;

&lt;p&gt;Code as &amp;lsquo;PLAY&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;babylanguage1&amp;gt;&lt;/code&gt;: Refers to infant&amp;rsquo;s predominant language spoken during the session.&lt;/p&gt;

&lt;p&gt;Code with lowercase, full name of the language: &amp;lsquo;english&amp;rsquo; or &amp;lsquo;spanish&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;babylanguage2&amp;gt;&lt;/code&gt;: Refers to infant&amp;rsquo;s other language spoken during the session, if another language was spoken.&lt;/p&gt;

&lt;p&gt;Code with lowercase, full name of the language: &amp;lsquo;english&amp;rsquo; or &amp;lsquo;spanish&amp;rsquo;. If no other language was spoken as missing &amp;lsquo;.&amp;rsquo;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;momlanguage1&amp;gt;&lt;/code&gt;: Refers to mother&amp;rsquo;s predominant language spoken during the session.&lt;/p&gt;

&lt;p&gt;Code with lowercase, full name of the language: &amp;lsquo;english&amp;rsquo; or &amp;lsquo;spanish&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;momlanguage2&amp;gt;&lt;/code&gt;: Refers to mother&amp;rsquo;s other language spoken during the session, if another language was spoken.&lt;/p&gt;

&lt;p&gt;Code with lowercase, full name of the language: &amp;lsquo;english&amp;rsquo; or &amp;lsquo;spanish&amp;rsquo;. If no other language was spoken as missing &amp;lsquo;.&amp;rsquo;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/study/coding/communication/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0400</pubDate>
      
      <guid>/study/coding/communication/</guid>
      <description>

&lt;h1 id=&#34;coding-communication-communication-html&#34;&gt;Coding &lt;a href=&#34;communication.html&#34; target=&#34;_blank&#34;&gt;communication&lt;/a&gt;&lt;/h1&gt;

&lt;h2 id=&#34;babyvoc&#34;&gt;&lt;code&gt;babyvoc&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;content&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;general-orientation&#34;&gt;General Orientation&lt;/h3&gt;

&lt;p&gt;Contains a transcript of all of the utterances/vocalizations of the baby.&lt;/p&gt;

&lt;p&gt;This column is automatically populated after the transcribe pass is completed using a Ruby script.
All of the utterances tagged with &amp;lsquo;b&amp;rsquo; in &lt;source&gt; in transcribe are transferred here.
The onset and offset are equal, and set to the onset from the transcribe column, which reflects a time as close as possible to the onset of that utterance.&lt;/p&gt;

&lt;h2 id=&#34;babyutterancetype&#34;&gt;&lt;code&gt;babyutterancetype&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;language_s-w&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;langlike-b-v&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;crygrunt_c-g&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;unintell-x&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;general-orientation-1&#34;&gt;General Orientation&lt;/h3&gt;

&lt;p&gt;Utterance type = categorization of previously coded utterances as a specific type of speech form.
Read the utterance transcribed in babyvoc column and categorize each utterance based on codes below.&lt;/p&gt;

&lt;p&gt;Codes are mutually exclusive.
The prompts/arguments in the code are designed to speed the coder through the easiest to detect and easiest to code categories (language, language-like sounds, etc.) down through the more nuanced and time-consuming codes.
Once the proper code has been found, enter it into the prompt you are at, then code all of the rest as periods ”.”. For instance, if the baby didn&amp;rsquo;t speak in full speech, or speech-like sound, but did cry/scream, then code &amp;lt;.,.,c,.&amp;gt;.&lt;/p&gt;

&lt;p&gt;The transcript will expedite this process. Double check and listen again as you read the transcript. Comment any disagreements.&lt;/p&gt;

&lt;h3 id=&#34;value-list&#34;&gt;Value List&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;language_s-w&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;s&lt;/code&gt; = sentence&lt;/p&gt;

&lt;p&gt;&lt;code&gt;w&lt;/code&gt; = word&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;langlike_b-v&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;b&lt;/code&gt; = babble&lt;/p&gt;

&lt;p&gt;&lt;code&gt;v&lt;/code&gt; = vowel&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;crygrunt_c-g&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;c&lt;/code&gt; = cry&lt;/p&gt;

&lt;p&gt;&lt;code&gt;g&lt;/code&gt; = grunt&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;unintell-x&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;x&lt;/code&gt; = unintelligible&lt;/p&gt;

&lt;h3 id=&#34;operational-definitions&#34;&gt;Operational Definitions&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;s&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Sentence = an utterance in which the speaker utters more than one word, producing a sentence or phrase (e.g., “Daddy&amp;rsquo;s shoe” or “Go to the park”).&lt;/p&gt;

&lt;p&gt;Transcription: “ooh gimme that”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63348/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63348/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63348/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcription: “i take this”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63350/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63350/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63350/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcription: “goodbye sad face?”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63354/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63354/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63354/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;w&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Word = an utterance in which the speaker utters a single word, such as “dolly” or “ball.”&lt;/p&gt;

&lt;p&gt;Transcription: “cars”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63352/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63352/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63352/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcription: “basketball”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63356/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63356/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63356/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcription: “truck”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63358/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63358/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63358/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;b&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Babble = an utterance in which the speaker utters a series of repeated canonical syllables, such as ba-ba-ba, or ga-ga-ga.&lt;/p&gt;

&lt;p&gt;Transcription: “b”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63334/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63334/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63334/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcription: “b”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63338/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63338/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63338/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcription: “b”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63340/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63340/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63340/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;v&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Vowel = an utterance in which the speaker utters a vowel sound (e.g, /a/, /i:/).&lt;/p&gt;

&lt;p&gt;Transcription: “v”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63342/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63342/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63342/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcription: “v”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63344/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63344/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63344/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcription: “v”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63346/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63346/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63346/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;c&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Cry = an utterance in which the speaker is experiencing a period of prolonged distress.&lt;/p&gt;

&lt;p&gt;Transcription: “c”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63746/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63746/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63746/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcription: “c”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63749/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63749/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63749/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcription: “c”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63752/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63752/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63752/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;g&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Grunt = an utterance in which the speaker produces a low, short, inarticulate, guttural sound often used to express effort or exertion.
Vegetative sounds, such as coughing and sneezing, should be captured using this code.&lt;/p&gt;

&lt;!-- Should this be &#34;g&#34;? --&gt;

&lt;p&gt;Transcription: “c”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63747/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63747/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63747/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;!-- Should this be &#34;g&#34;? --&gt;

&lt;p&gt;Transcription: “c”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63753/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63753/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63753/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;x&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Unintelligible = either what the baby said was not intelligible to the transcriber, or after listening you are not able to understand well enough what they say even with the transcript to properly code it.&lt;/p&gt;

&lt;h3 id=&#34;how-to-code&#34;&gt;How to Code&lt;/h3&gt;

&lt;p&gt;Set the “JUMP-BACK-BY” to 2 s.&lt;/p&gt;

&lt;p&gt;Hit “FIND” on the controller to go to the onset of each utterance, which was populated in babyvoc column.
JUMP-BACK-BY 2 s so the utterance can be viewed in context.&lt;/p&gt;

&lt;p&gt;Play in real time to code each utterance, which is coded in mutually exclusive categories. TAB to between each argument/prompt inserting period “.” until you reach the appropriate code.
Then insert periods to the end of the cell.&lt;/p&gt;

&lt;h2 id=&#34;momspeech&#34;&gt;&lt;code&gt;momspeech&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;content&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;general-orientation-2&#34;&gt;General Orientation&lt;/h3&gt;

&lt;p&gt;Contains a transcript of all of the utterances of the mom.&lt;/p&gt;

&lt;p&gt;This column is automatically populated after the transcribe pass is completed using a Ruby script.
All of the utterances tagged with &amp;rsquo;m&amp;rsquo; in &lt;source&gt; in transcribe are transferred here.
The onset and offset are equal, and set to the onset from the transcribe column, which reflects a time as close as possible to the onset of that utterance.&lt;/p&gt;

&lt;h2 id=&#34;momutterancetype&#34;&gt;&lt;code&gt;momutterancetype&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;imperative_l-a-p&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;interrog-i_declar-d&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;filler-f&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;unintell-x&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;general-orientation-3&#34;&gt;General Orientation&lt;/h3&gt;

&lt;p&gt;Utterance type = categorization of previously coded utterances as a specific type of speech form.
Read the utterance transcribed in &lt;code&gt;momspeech&lt;/code&gt; column and categorize each utterance based on codes below.&lt;/p&gt;

&lt;p&gt;Codes are mutually exclusive.
The prompts/arguments in the code are designed to speed the coder through the easiest to detect and easiest to code categories (imperatives, then interrogatives, declaratives, etc.) down through the more nuanced and time-consuming codes.
After the proper code has been found, enter it into the prompt you are at, then code all of the rest as periods “.”.
For instance, if the mom didn&amp;rsquo;t do an imperative, sing/read, but did give a declarative, then code &amp;lt;.,d,.,.&amp;gt;.&lt;/p&gt;

&lt;p&gt;What is coded is not solely based on the transcript. Listen to the audio, watch the video, and read the transcript so you are sure of the intent behind the mom&amp;rsquo;s speech.&lt;/p&gt;

&lt;h3 id=&#34;value-list-1&#34;&gt;Value List&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;imperative_l-a-p&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;l&lt;/code&gt; = imperative look&lt;/p&gt;

&lt;p&gt;&lt;code&gt;a&lt;/code&gt; = imperative act&lt;/p&gt;

&lt;p&gt;&lt;code&gt;p&lt;/code&gt; = imperative prohibit&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;interrog-i_declar-d&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;i&lt;/code&gt; = interrogative`&lt;/p&gt;

&lt;p&gt;&lt;code&gt;d&lt;/code&gt; = declarative&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;filler-f&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;f&lt;/code&gt; = filler/affirmation&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;unintell-x&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;x&lt;/code&gt; = unintelligible&lt;/p&gt;

&lt;h3 id=&#34;operational-definitions-1&#34;&gt;Operational Definitions&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;l&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Imperative Look = an utterance in which the speaker directs a baby&amp;rsquo;s attention (e.g., “Look here”, “See?”, or calls baby&amp;rsquo;s name to alert attention).&lt;/p&gt;

&lt;p&gt;Transcript: “evelyn”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63370/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63370/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63370/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcript: “look”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63374/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63374/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63374/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;a&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Imperative Act = an utterance in which the speaker directs a baby&amp;rsquo;s action, such as asking baby to do something, or to play with an object. An example would be if a mother tells her baby “let&amp;rsquo;s play with the ball”.&lt;/p&gt;

&lt;p&gt;Transcript: “turn the page”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63376/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63376/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63376/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcript: “come here please”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63378/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63378/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63378/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcript: “go get the basketball”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63392/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63392/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63392/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: The imperative look and imperative act can be collapsed if the breakdown takes too long to code/specify (although we don&amp;rsquo;t think it will save time).&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;p&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Imperative Prohibit = an utterance in which the speaker prohibits a baby&amp;rsquo;s behavior, such as asking baby to stop what they&amp;rsquo;re doing.&lt;/p&gt;

&lt;p&gt;Transcript: “dont knock it over”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63380/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63380/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63380/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcript: “dont be so rough”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63394/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63394/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63394/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcript: “no no tv”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63755/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63755/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63755/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;i&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Interrogative = an utterance in which the speaker asks for information about objects or ongoing activities (e.g., “What is this called?”, “What color is this?).
                                                                    Questions that start with “Can you” or “Would you” (e.g., “Can you put that down”) should not be considered for interrogatives. Their function is to regulate the baby&amp;rsquo;s behavior and should be coded as imperatives. Tag questions, in which the speaker adds a question at the end of a statement (“That&amp;rsquo;s a blue truck, right?”) are not considered questions. These should be coded as declaratives.&lt;/p&gt;

&lt;p&gt;Transcript: “how does the pig say?”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63386/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63386/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63386/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcript: “what is this?”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63390/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63390/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63390/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;d&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Declarative= an utterance in which the speaker provides information about objects, events or ongoing activities (e.g., “This is a fun toy”; “Red truck”; “You are stirring in the cup”.&lt;/p&gt;

&lt;p&gt;Transcript: “baby&amp;rsquo;s clothes”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63368/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63368/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63368/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcript: “thats a lemonade”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63388/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63388/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63388/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;f&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Affirmations/Fillers = an utterance in which the speaker is recognizing another speaker&amp;rsquo;s behavior and agreeing with it, or using words as conversational fillers.
For instance, when the mother says “There you go” when the baby successfully completes a puzzle, or when she says “yeah”, or “uhuh”.&lt;/p&gt;

&lt;p&gt;Transcript: “wow”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63396/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63396/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63396/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcript: “there you go”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63757/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63757/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63757/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;x&amp;gt;&lt;/code&gt;
                                                                    Unintelligible = either what the mom said was not intelligible to the transcriber, or after listening you are not able to understand well enough what they say even with the transcript to properly code it.&lt;/p&gt;

&lt;p&gt;Transcript: “xxx”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63410/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63410/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63410/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Transcript: “xxx”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63412/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63412/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63412/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;how-to-code-1&#34;&gt;How to Code&lt;/h3&gt;

&lt;p&gt;Set the JUMP-BACK-BY key for 2 s.
Hit “FIND” on the controller to go to the onset of each utterance, which was populated in momspeech column.&lt;/p&gt;

&lt;p&gt;JUMP-BACK-BY 2 s so the utterance can be viewed in context.
Play in real time to code each utterance, which is coded in mutually exclusive categories.&lt;/p&gt;

&lt;p&gt;TAB between each argument/prompt inserting period ”.“ until you reach the appropriate code. Then insert periods to the end of the cell.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/study/coding/emotion/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0400</pubDate>
      
      <guid>/study/coding/emotion/</guid>
      <description>

&lt;h1 id=&#34;coding-emotion-emotion-html&#34;&gt;Coding &lt;a href=&#34;emotion.html&#34; target=&#34;_blank&#34;&gt;emotion&lt;/a&gt;&lt;/h1&gt;

&lt;h2 id=&#34;babyemotion&#34;&gt;&lt;code&gt;babyemotion&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;emotion_p-n&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;general-orientation&#34;&gt;General Orientation&lt;/h3&gt;

&lt;p&gt;This code captures the times that the baby is clearly displaying positive or negative emotion through facial expressions.
Times when the baby is in neutral emotion are not marked.
Bouts of emotion as scored as events, where the grey spaces between emotion events mean the baby is neutral or emotion is unclear.
Coders also mark times as “missing” when the baby&amp;rsquo;s face could not possibly be coded for emotion (e.g., face completely turned away from camera, baby&amp;rsquo;s head out of the video).
When the baby&amp;rsquo;s face is clearly not visible, negative emotion may be coded only if there is absolute clear vocal affect (e.g., baby is screaming and crying).&lt;/p&gt;

&lt;p&gt;Coders are watching/tagging the duration of each positive or negative emotion event by marking onset/offset times.
To determine emotion, coders are watching the baby&amp;rsquo;s face, not vocal affect.
To determine if emotion is not codeable/missing, coders are watching for when the face fully moves out of the camera view.&lt;/p&gt;

&lt;h3 id=&#34;value-list&#34;&gt;Value List&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;p&lt;/code&gt; = positive emotion&lt;/p&gt;

&lt;p&gt;&lt;code&gt;n&lt;/code&gt; = negative emotion&lt;/p&gt;

&lt;p&gt;&lt;code&gt;.&lt;/code&gt; = baby&amp;rsquo;s face is completely not visible&lt;/p&gt;

&lt;h3 id=&#34;operational-definitions&#34;&gt;Operational Definitions&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;p&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code &amp;lsquo;p&amp;rsquo; when the baby is clearly displaying positive emotion (e.g.,
smiling).
Code based off of the face and not off of the voice. Look for raising of the corners of the mouth, grinning and showing the teeth, along with closing of the eyes because of the raised cheeks.
If there is any doubt that the baby is showing positive emotion, then do not begin the code.&lt;/p&gt;

&lt;p&gt;Positive emotion cannot be coded based on the voice alone.
So positive emotion could not be scored when the baby&amp;rsquo;s face is absolutely not visible (i.e. missing).&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;n&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code &amp;lsquo;n&amp;rsquo; when the baby is clearly displaying negative emotion (e.g., frowning, wincing).
Code based off of the face and not off of the voice. Look for lowering of the corners of the mouth, stretching and tautness of the lips, along with closing of the eyes because of furrowed brow.
If there is any doubt that the baby is showing negative emotion, then do not begin the code.&lt;/p&gt;

&lt;p&gt;Do not defer to the voice to code negative emotion when the face is visible.
If the baby&amp;rsquo;s face is clearly not visible (i.e. missing), then &amp;lsquo;n&amp;rsquo; can be coded if the baby is displaying clear negative emotion through their voice.
The baby could be screaming, crying, or yelling.
If there is any doubt whether the voice is negative, then do not begin the code.&lt;/p&gt;

&lt;h4 id=&#34;onset&#34;&gt;Onset&lt;/h4&gt;

&lt;p&gt;Onset of an emotion event is the first frame the baby is clearly displaying positive/negative emotion through the face.
The onset does not need to be completely frame accurate, since emotion could begin in any part of the face.
The coder is looking to identify when any lay person would absolutely agree the baby is showing positive/negative emotion based on the face.&lt;/p&gt;

&lt;p&gt;There is no criterion for how long an emotion event should be.
It is easy for the coder to mark the first frame when they see clear positive/negative emotion, even if it ends a few frames later.
Events that are later deemed “too brief” could be removed via scripting.&lt;/p&gt;

&lt;p&gt;When coding &amp;lsquo;n&amp;rsquo; from voice during missing time, set the onset when the negative voice starts and end the &amp;lsquo;n&amp;rsquo; code when the voice ends.
The onset/offset do not need to be frame accurate.
For cases when emotion code begins right out of missing: The face has not been visible and the first frame you can see the face again the infant is clearly displaying positive/negative emotion.
Code the onset of the emotion code as the first frame when the face reappears. Use the “0” key to set the onset of the emotion event and simultaneously set the offset of &amp;lsquo;missing&amp;rsquo;.
We want to preserve the 1ms difference between &amp;lsquo;missing&amp;rsquo; and the emotion code so we can know that that &amp;lsquo;missing&amp;rsquo; event was ended because of the onset of an emotion code.&lt;/p&gt;

&lt;h4 id=&#34;offset&#34;&gt;Offset&lt;/h4&gt;

&lt;p&gt;Offset of a positive/negative emotion is the first frame the baby is clearly back to a neutral emotion through the face.
The offset does not need to completely frame accurate, since emotion could end in any part of the face.
The coder is looking to identify when any lay person would absolutely agree the baby is no longer showing any positive/negative emotion based on the face.&lt;/p&gt;

&lt;p&gt;If the baby&amp;rsquo;s face returns to neutral for less than 5 frames during one emotion code (e.g. positive, then neutral for 4 frames, then back to positive), continue the &amp;lsquo;p&amp;rsquo; or &amp;lsquo;n&amp;rsquo; code.
The coder would have to expend unneeded effort to identify and tag those offsets and onsets time, since reliability does not need to be frame accurate.&lt;/p&gt;

&lt;p&gt;For cases when emotion code is ended by missing: The emotion event may or may not have ended but the coder can no longer see the face to code offset.
Code the offset as the first frame the face completely is not visible (see &amp;lsquo;missing&amp;rsquo; code below).
Use “0” key to set the offset of emotion and simultaneously code the onset of &amp;lsquo;missing&amp;rsquo;.
We want to preserve the 1ms difference between the emotion code and &amp;lsquo;missing&amp;rsquo; so we can know that that &amp;lsquo;missing&amp;rsquo; event caused the offset of that emotion event.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;.&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code &amp;lsquo;.&amp;rsquo; for missing when the baby&amp;rsquo;s face is completely not visible.
The baby&amp;rsquo;s full face could turned away from the camera, baby&amp;rsquo;s head is completely off camera, or the baby is out of frame entirely.
If the coder could see the emotion the baby is expressing in their face from a side or oblique angle, then do not code missing.&lt;/p&gt;

&lt;p&gt;If the face is not visible but the baby is displaying clear negative emotion in the voice (e.g., baby crying or screaming) then the missing code is ended and &amp;lsquo;n&amp;rsquo; is coded (see &amp;lsquo;n&amp;rsquo; code). Positive emotion cannot be coded by voice.&lt;/p&gt;

&lt;p&gt;Onset is the first frame in which the coder clearly cannot see the face.
Offset is the first frame in which the coder can clearly see the face again.
The onset and offset do not need to be completely frame accurate, since reliability does not need to be exact from accurate.&lt;/p&gt;

&lt;p&gt;If the baby&amp;rsquo;s face was &amp;lsquo;missing&amp;rsquo; and then reappeared for less than 5 frames, don’t stop the &amp;lsquo;.&amp;rsquo; code to mark those few frames.&lt;/p&gt;

&lt;h3 id=&#34;how-to-code&#34;&gt;How to Code&lt;/h3&gt;

&lt;p&gt;Set “JUMP-BACK-BY” key to 1 s.&lt;/p&gt;

&lt;p&gt;Play with #8-PLAY in real time (1x speed) until the baby changes to clear positive or clear negative emotion or the face is clearly not visible.
Focus on the baby&amp;rsquo;s face and do not be distracted by what the baby is saying or doing.&lt;/p&gt;

&lt;p&gt;Pause with #5-STOP once you have identified a clear change in emotion or that the baby&amp;rsquo;s face is no longer visible at all.
Shuttle back with #4-SHUTTLEBACK at &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;8&lt;/sub&gt;-1/4x speed to identify the onset. Use the mouth and eyes as the guide to onset.
Press ENTER to set the onset as the frame where any lay person would say that baby is happy or sad.
The coder may even feel happy or sad watching the baby&amp;rsquo;s face; use this as a guide for onset.&lt;/p&gt;

&lt;p&gt;Then hit #8-PLAY then #4-SHUTTLEBACK once to watch at 1/2x and look for the offset of that emotion or when the face comes completely back into view.
For missing, if it seems like there may be a long stretch of missing (e.g. baby has completely wandered out of the room) then watch at 1x or 2x speed—but be listening in case there is negative emotion in the voice.
Pause when you identify the offset.&lt;/p&gt;

&lt;p&gt;Hit #1-JOGBACK and #3-JOGFORWARD to tag the frame the baby&amp;rsquo;s face is clearly not positive or not negative (returned to neutral) or the face is visible again to code emotion from.&lt;/p&gt;

&lt;p&gt;Then return to real time (1x speed) with #8-PLAY to watch for the next event.&lt;/p&gt;

&lt;h2 id=&#34;momemotion&#34;&gt;&lt;code&gt;momemotion&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;emotion_p-n&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;general-orientation-1&#34;&gt;General Orientation&lt;/h3&gt;

&lt;p&gt;This code captures the times that the mom is clearly displaying positive or negative emotion through facial expressions.
Times when the mom is in neutral emotion are not marked. Bouts of emotion as scored as events, where the grey spaces between emotion events mean the mom is neutral or emotion is unclear.
Coders also mark times as “missing” when the mom&amp;rsquo;s face could not possibly be coded for emotion (e.g., face completely turned away from camera, mom&amp;rsquo;s head out of the video).
When the mom&amp;rsquo;s face is clearly not visible, negative emotion may be coded only if there is absolute clear vocal affect (e.g., mom is yelling).&lt;/p&gt;

&lt;p&gt;Coders are watching/tagging the duration of each positive or negative emotion event by marking onset/offset times.
To determine emotion, coders are watching the mom&amp;rsquo;s face, not vocal affect.
To determine if emotion is not codeable/missing, coders are watching for when the face fully moves out of the camera view.&lt;/p&gt;

&lt;h3 id=&#34;value-list-1&#34;&gt;Value List&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;p&lt;/code&gt; = positive emotion&lt;/p&gt;

&lt;p&gt;&lt;code&gt;n&lt;/code&gt; = negative emotion&lt;/p&gt;

&lt;p&gt;&lt;code&gt;.&lt;/code&gt; = mom&amp;rsquo;s face is completely not visible&lt;/p&gt;

&lt;h3 id=&#34;operational-definitions-1&#34;&gt;Operational Definitions&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;p&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code &amp;lsquo;p&amp;rsquo; when the mom is clearly displaying positive emotion (e.g., smiling).
Code based off of the face and not off of the voice.
Look for raising of the corners of the mouth, grinning and showing the teeth, along with closing of the eyes because of the raised cheeks.
If there is any doubt that the mom is showing positive emotion, then do not begin the code.&lt;/p&gt;

&lt;p&gt;Positive emotion cannot be coded based on the voice alone.
So positive emotion could not be scored when the mom&amp;rsquo;s face is absolutely not visible (i.e. missing).&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;n&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code &amp;lsquo;n&amp;rsquo; when the mom is clearly displaying negative emotion (e.g., frowning, wincing).
Code based off of the face and not off of the voice.
Look for lowering of the corners of the mouth, stretching and tautness of the lips, along with closing of the eyes because of furrowed brow.
If there is any doubt that the mom is showing negative emotion, then do not begin the code.&lt;/p&gt;

&lt;p&gt;Do not defer to the voice to code negative emotion when the face is visible.
If the mom&amp;rsquo;s face is clearly not visible (i.e. missing), then &amp;lsquo;n&amp;rsquo; can be coded if the mom is displaying clear negative emotion through their voice.
The mom could be screaming or upset.
If there is any doubt whether the voice is negative, then do not begin the code.&lt;/p&gt;

&lt;h4 id=&#34;onset-1&#34;&gt;Onset&lt;/h4&gt;

&lt;p&gt;Onset of an emotion event is the first frame the mom is clearly displaying positive/negative emotion through the face.
The onset does not need to be completely frame accurate, since emotion could begin in any part of the face.
The coder is looking to identify when any lay person would absolutely agree the mom is showing positive/negative emotion based on the face.&lt;/p&gt;

&lt;p&gt;There is no criterion for how long an emotion event should be.
It is easy for the coder to mark the first frame when they see clear positive/negative emotion, even if it ends a few frames later.
Events that are later deemed “too brief” could be removed via scripting.&lt;/p&gt;

&lt;p&gt;When coding &amp;lsquo;n&amp;rsquo; from voice during missing time, set the onset when the negative voice starts and end the &amp;lsquo;n&amp;rsquo; code when the voice ends.
The onset/offset do not need to be frame accurate.
For cases when emotion code begins right out of missing: The face has not been visible and the first frame you can see the face again the infant is clearly displaying positive/negative emotion.
Code the onset of the emotion code as the first frame when the face reappears. Use the “0” key to set the onset of the emotion event and simultaneously set the offset of &amp;lsquo;missing&amp;rsquo;.
We want to preserve the 1ms difference between &amp;lsquo;missing&amp;rsquo; and the emotion code so we can know that that &amp;lsquo;missing&amp;rsquo; event was ended because of the onset of an emotion code.&lt;/p&gt;

&lt;h4 id=&#34;offset-1&#34;&gt;Offset&lt;/h4&gt;

&lt;p&gt;Offset of a positive/negative emotion is the first frame the mom is clearly back to a neutral emotion through the face.
The offset does not need to completely frame accurate, since emotion could end in any part of the face.
The coder is looking to identify when any lay person would absolutely agree the mom is no longer showing any positive/negative emotion based on the face.&lt;/p&gt;

&lt;p&gt;If the mom&amp;rsquo;s face returns to neutral for less than 5 frames during one emotion code (e.g. positive, then neutral for 4 frames, then back to positive), continue the &amp;lsquo;p&amp;rsquo; or &amp;lsquo;n&amp;rsquo; code.
The coder would have to expend unneeded effort to identify and tag those offsets and onsets time, since reliability does not need to be frame accurate.&lt;/p&gt;

&lt;p&gt;For cases when emotion code is ended by missing: The emotion event may or may not have ended but the coder can no longer see the face to code offset.
Code the offset as the first frame the face completely is not visible (see &amp;lsquo;missing&amp;rsquo; code below).
Use “0” key to set the offset of emotion and simultaneously code the onset of &amp;lsquo;missing&amp;rsquo;.
We want to preserve the 1ms difference between the emotion code and &amp;lsquo;missing&amp;rsquo; so we can know that that &amp;lsquo;missing&amp;rsquo; event caused the offset of that emotion event.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;.&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code &amp;lsquo;.&amp;rsquo; for missing when the mom&amp;rsquo;s face is completely not visible.
The mom&amp;rsquo;s full face could turned away from the camera, mom&amp;rsquo;s head is completely off camera, or the mom is out of frame entirely.
If the coder could see the emotion the mom is expressing in their face from a side or oblique angle, then do not code missing.&lt;/p&gt;

&lt;p&gt;If the face is not visible but the mom is displaying clear negative emotion in the voice (e.g., mom yelling) then the missing code is ended and &amp;lsquo;n&amp;rsquo; is coded (see &amp;lsquo;n&amp;rsquo; code). Positive emotion cannot be coded by voice.&lt;/p&gt;

&lt;p&gt;Onset is the first frame in which the coder clearly cannot see the face. Offset is the first frame in which the coder can clearly see the face again.
The onset and offset do not need to be completely frame accurate, since reliability does not need to be exact from accurate.&lt;/p&gt;

&lt;p&gt;If the mom&amp;rsquo;s face was &amp;lsquo;missing&amp;rsquo; and then reappeared for less than 5 frames, don’t stop the &amp;lsquo;.&amp;rsquo; code to mark those few frames.&lt;/p&gt;

&lt;h3 id=&#34;how-to-code-1&#34;&gt;How to Code&lt;/h3&gt;

&lt;p&gt;Set “JUMP-BACK-BY” key to 1 s.&lt;/p&gt;

&lt;p&gt;Play with #8-PLAY in real time (1x speed) until the mom changes to clear positive or clear negative emotion or the face is clearly not visible.
Focus on the mom&amp;rsquo;s face and do not be distracted by what the mom is saying or doing.&lt;/p&gt;

&lt;p&gt;Pause with #5-STOP once you have identified a clear change in emotion or that the mom&amp;rsquo;s face is no longer visible at all.
Shuttle back with #4-SHUTTLEBACK at &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;8&lt;/sub&gt;-1/4x speed to identify the onset.
Use the mouth and eyes as the guide to onset.
Press ENTER to set the onset as the frame where any lay person would say that mom is happy or sad.
The coder may even feel happy or sad watching the mom&amp;rsquo;s face; use this as a guide for onset.&lt;/p&gt;

&lt;p&gt;Then hit #8-PLAY then #4-SHUTTLEBACK once to watch at 1/2x and look for the offset of that emotion or when the face comes completely back into view.
For missing, if it seems like there may be a long stretch of missing (e.g. mom is on a different side of the room from the baby) then watch at 1x or 2x speed—but be listening in case there is negative emotion in the voice.
Pause when you identify the offset.&lt;/p&gt;

&lt;p&gt;Hit #1-JOGBACK and #3-JOGFORWARD to tag the frame the mom&amp;rsquo;s face is clearly not positive or not negative (returned to neutral) or the face is visible again to code emotion from.&lt;/p&gt;

&lt;p&gt;Then return to real time (1x speed) with #8-PLAY to watch for the next event.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/study/coding/gesture/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0400</pubDate>
      
      <guid>/study/coding/gesture/</guid>
      <description>

&lt;h1 id=&#34;coding-gesture-gesture-html&#34;&gt;Coding &lt;a href=&#34;gesture.html&#34; target=&#34;_blank&#34;&gt;gesture&lt;/a&gt;&lt;/h1&gt;

&lt;h2 id=&#34;gesture&#34;&gt;&lt;code&gt;gesture&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;source_m-b&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;gesture_p-s-i-c&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;general-orientation&#34;&gt;General Orientation&lt;/h3&gt;

&lt;p&gt;Gestures are segmented, &lt;a href=&#34;https://www.dictionary.com/browse/durative&#34; target=&#34;_blank&#34;&gt;durative&lt;/a&gt;, event-based behaviors.
Watch the video paying attention to the communicative gestures used by the parent and the child.
When coding for gesture, focus on the mother’s or baby’s hands and head.&lt;/p&gt;

&lt;p&gt;Code mother and baby gesture simultaneously in one pass. Then based on the &lt;code&gt;&amp;lt;source&amp;gt;&lt;/code&gt; of the gesture, a script breaks apart mom and baby into separate babygesture and momgesture columns.&lt;/p&gt;

&lt;p&gt;Only onsets are coded to expedite coding; offsets could be coded later if duration of gesture or overlap with specific other domains is of interest.&lt;/p&gt;

&lt;h3 id=&#34;value-list&#34;&gt;Value List&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;source_m-b&amp;gt;&lt;/code&gt;
&lt;code&gt;m&lt;/code&gt; = mom
&lt;code&gt;b&lt;/code&gt; = baby
&lt;code&gt;h&lt;/code&gt; = mom holding baby&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;gesture_p-s-i-c&amp;gt;&lt;/code&gt;
&lt;code&gt;p&lt;/code&gt; = point
&lt;code&gt;s&lt;/code&gt; = show/hold up
&lt;code&gt;i&lt;/code&gt; = iconic gesture
&lt;code&gt;c&lt;/code&gt; = conventional gesture&lt;/p&gt;

&lt;h3 id=&#34;operational-definitions&#34;&gt;Operational Definitions&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;source_m-b&amp;gt;&lt;/code&gt;
&lt;code&gt;&amp;lt;m&amp;gt;&lt;/code&gt;: Code &amp;rsquo;m&amp;rsquo; if the mom is the source of the gesture.
&lt;code&gt;&amp;lt;b&amp;gt;&lt;/code&gt;: Code &amp;lsquo;b&amp;rsquo; if the baby is the source of the gesture.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;gesture_p-s-i-c&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Gesturing by either mom or baby to the investigator, or anyone else in the room, should not be coded.
The following should NOT be coded as gestures: tapping baby to get his/her attention; pushing an object away; hugging and kissing; one partner moving the other&amp;rsquo;s hand (e.g., to initiate contact, like proximity seeking); jerking the head to indicate “come here.”&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;p&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code &amp;lsquo;p&amp;rsquo; when the baby or mom extends their index finder to indicate reference to objects, people, events, or locations in the environment.&lt;/p&gt;

&lt;p&gt;Onset is the frame when the finger is fully extended in space toward a referent, or when the point finger is extended and makes contact with the object.
Repetitive points should be coded as separate gesture events.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;s&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code &amp;rsquo;s&amp;rsquo; when the baby or mom holds up an object to present it as if to say: “look at this” or “do you want this” or “I want you to take this”.
Given that it’s not possible to distinguish intention, when a participant shows, offers, or gives an object (e.g., baby actually hands toy to mom, offering toy to mom but mom doesn’t take) code as &amp;rsquo;s&amp;rsquo;, to save decision-making time.&lt;/p&gt;

&lt;p&gt;Onset is the frame when the object is fully held up or out to show it. Repetitive instances of holding up or offering an object should be coded as separate gesture events.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;i&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code &amp;lsquo;i&amp;rsquo; when the baby or mom engages in an iconic gesture.
They are called iconic because they represent an object, idea, or action that can&amp;rsquo;t easily be referenced with a deictic (point/show) or conventional gesture.
The movement of these gestures usually calls to mind something about the nature of the object, idea or action being referenced.
For example, you could move your arms back and forth to represent running, or you could trace a square in the air with your finger, or flap your arms as if flying.&lt;/p&gt;

&lt;p&gt;Onset is the frame when the baby or mom has clearly begun the iconic gesture, and the coder can clearly identify this a gesture but does fall into the conventional gesture category (see &lt;code&gt;&amp;lt;c&amp;gt;&lt;/code&gt;). Repetitive instances of an iconic gesture should be coded as separate gesture events.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;c&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code &amp;lsquo;c&amp;rsquo; when the baby or mom engages in a conventional gesture. Conventional gestures are culturally-agreed-upon hand or head movements with a specific meaning, like nodding the head to mean “yes,” shaking the head to mean “no,” and moving the finger to lips to indicate “be quiet”.&lt;/p&gt;

&lt;p&gt;shaking head “no”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/20618,23455/asset/76362/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/20618,23455/asset/76362/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/20618,23455/asset/76362/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;holding out hand for “give me”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/20618,23455/asset/76362/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/20618,23455/asset/76362/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/20618,23455/asset/76362/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If a gesture is conventional, you should be able to understand its meaning just by seeing it in isolation, without knowing any of the context.
Some additional examples of conventional gestures include: waving, clapping, flipping arms out to side to indicate “I don’t know’ or “where is it”, come here gesture (finger motions or palms), sit down gesture (pats ground), pickup gesture (child holds up arms to be picked up), thumbs up, shrugs, naughties (wag finger), hug me (hold arms out asking for hug), etc.&lt;/p&gt;

&lt;p&gt;Onset is the frame when the baby or mom has clearly begun the conventional gesture, and the coder can clearly identify this a gesture but does fall into the iconic gesture category (see &lt;code&gt;&amp;lt;i&amp;gt;&lt;/code&gt;).
Repetitive instances of a conventional gesture should be coded as separate gesture events.&lt;/p&gt;

&lt;h3 id=&#34;how-to-code&#34;&gt;How to Code&lt;/h3&gt;

&lt;p&gt;Set “JUMP-BACK-BY” key to 2 s.&lt;/p&gt;

&lt;p&gt;Gestures are best coded with the volume low or muted so that the language content does not confound the coding process.&lt;/p&gt;

&lt;p&gt;Watch in 1x speed until either mom or baby gestures. Focus on the mom’s and infant’s hands and head to identify instances of gestures.&lt;/p&gt;

&lt;p&gt;Gestures are defined purely as they relate to the communicative nature of each action. The coder can establish whether something is communicative by looking at things like eye contact, conversational context, and the reaction of the person being spoken or gestured to. If the movement isn’t supposed to communicate anything, then it’s not a gesture. For example, a child might reach for an object and pick it up and look at it. This is an action, not a gesture. But, if the child points to the object to indicate its presence, or if the parent claps her hands to indicate “good job,” then these are gestures. (If there is significant ambiguity in whether a gesture is communicative, or how to code it, sound may be of assistance.)&lt;/p&gt;

&lt;p&gt;When the coder identifies a mom or baby gesturing, jump back 2 seconds and play the video again at ½ speed until the frame the gesture is clearly underway is found. Hit the = key (equal sign) to insert a point cell; so the current video frame becomes the onset and the offset.&lt;/p&gt;

&lt;p&gt;Type &amp;rsquo;m&amp;rsquo; or &amp;lsquo;b&amp;rsquo; to indicate whether mom of the baby was the &lt;source&gt; of the gesture. Hit the TAB key to advance the cursor to &lt;gesture&gt;, then type &amp;lsquo;p&amp;rsquo;, &amp;rsquo;s&amp;rsquo;, &amp;lsquo;i&amp;rsquo;, or &amp;lsquo;c&amp;rsquo; to indicate the type of gesture.&lt;/p&gt;

&lt;p&gt;Splitting Mom and Baby Gestures
It&amp;rsquo;s faster to code mom and baby gesture together in one pass. But for consistency with the other coding passes, we want mom speech and baby gestures to be in two separate columns.&lt;/p&gt;

&lt;p&gt;Run the Split-MomBabyGesture.rb script to pull baby and mom gestures from the the gesture column into babygesture and momgesture columns.&lt;/p&gt;

&lt;h2 id=&#34;babygesture&#34;&gt;&lt;code&gt;babygesture&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;gesture_p-s-i-c&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;general-orientation-1&#34;&gt;General Orientation&lt;/h3&gt;

&lt;p&gt;Contains gestures produced by the baby.&lt;/p&gt;

&lt;p&gt;This column is automatically populated after the gesture pass is completed, using a Ruby script. All of the gestures tagged with &amp;lsquo;b&amp;rsquo; in &lt;source&gt; in the gesture column are transferred here. The onset and offset are equal, and set to the onset from the gesture column, which reflects the time when the coder was sure the gesture had begun.&lt;/p&gt;

&lt;h3 id=&#34;value-list-1&#34;&gt;Value List&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;gesture_p-s-i-c&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;p&lt;/code&gt; = point&lt;/p&gt;

&lt;p&gt;&lt;code&gt;s&lt;/code&gt; = show/hold up&lt;/p&gt;

&lt;p&gt;&lt;code&gt;i&lt;/code&gt; = iconic gesture&lt;/p&gt;

&lt;p&gt;&lt;code&gt;c&lt;/code&gt; = conventional gesture&lt;/p&gt;

&lt;h2 id=&#34;momgesture&#34;&gt;&lt;code&gt;momgesture&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;gesture_p-s-i-c&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;general-orientation-2&#34;&gt;General Orientation&lt;/h3&gt;

&lt;p&gt;Contains gestures produced by the mom.&lt;/p&gt;

&lt;p&gt;This column is automatically populated after the gesture pass is completed, using a Ruby script.
All of the gestures tagged with &amp;rsquo;m&amp;rsquo; in &lt;source&gt; in the gesture column are transferred here.
The onset and offset are equal, and set to the onset from the gesture column, which reflects the time when the coder was sure the gesture had begun.&lt;/p&gt;

&lt;h3 id=&#34;value-list-2&#34;&gt;Value List&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;gesture_p-s-i-c&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;p&lt;/code&gt; = point&lt;/p&gt;

&lt;p&gt;&lt;code&gt;s&lt;/code&gt; = show/hold up&lt;/p&gt;

&lt;p&gt;&lt;code&gt;i&lt;/code&gt; = iconic gesture&lt;/p&gt;

&lt;p&gt;&lt;code&gt;c&lt;/code&gt; = conventional gesture&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/study/coding/locomotion/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0400</pubDate>
      
      <guid>/study/coding/locomotion/</guid>
      <description>

&lt;h1 id=&#34;coding-locomotion-locomotion-html&#34;&gt;Coding &lt;a href=&#34;locomotion.html&#34; target=&#34;_blank&#34;&gt;locomotion&lt;/a&gt;&lt;/h1&gt;

&lt;h2 id=&#34;babyloc&#34;&gt;&lt;code&gt;babyloc&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;loc_l-f-h-c&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;general-orientation&#34;&gt;General Orientation&lt;/h3&gt;

&lt;p&gt;This code captures the times that the baby is engaged in self-generated locomotion in any form (i.e., bum shuffling, scooting, belly crawling, hands-knees crawling, cruising, supported walking, independent walking, etc.).&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62749/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62749/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62749/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62785/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62785/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62785/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Also included in this pass are the times when locomotion cannot occur because the baby is held,&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62751/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62751/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62751/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;and the times baby is constrained in baby furniture (e.g., a belted chair, highchair, or stroller).&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62753/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62753/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62753/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Coders score only instances of baby-generated locomotion, and instances of falling, being held, or being constrained.
Coders do not score instances where baby is stationary but could have locomoted.
Bouts of locomotion are scored as events, where the gray spaces between cells mean the baby is stationary but not held and not constrained.&lt;/p&gt;

&lt;p&gt;Coders are watching/tagging the duration of each of these events (locomotion, falls, held, constrained) by marking onset/offset times.
To determine locomotion, coders are watching for steps with the feet, the knees, or the bum.
Any other movements that are not initiated from these three body locations are considered to be a transition between postures and are subsumed by stationary, because it is not locomotion.&lt;/p&gt;

&lt;h3 id=&#34;value-list&#34;&gt;Value List&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;l&lt;/code&gt; = locomotion&lt;/p&gt;

&lt;p&gt;&lt;code&gt;f&lt;/code&gt; = fall&lt;/p&gt;

&lt;p&gt;&lt;code&gt;m&lt;/code&gt; = mother constraining baby locomotion&lt;/p&gt;

&lt;p&gt;&lt;code&gt;d&lt;/code&gt; = device constraining baby locomotion (high chair, stroller, carseat, etc.)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;.&lt;/code&gt; = when baby is off camera or the baby&amp;rsquo;s feet/knees/bum are off camera and coder cannot see or infer whether the baby is locomoting.&lt;/p&gt;

&lt;h3 id=&#34;operational-definitions&#34;&gt;Operational Definitions&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;l&amp;gt;&lt;/code&gt;
Code “l” when the baby is engaged in self-generated locomotion in any form (i.e., bum shuffling, scooting, belly crawling, hands-knees crawling, climbing, cruising, supported walking, independent walking, etc.)&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62761/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62761/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62761/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62769/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62769/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62769/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62771/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62771/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62771/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62773/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62773/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62773/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62783/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62783/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62783/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This code counts locomotion regardless of whether the baby maintains balance independently or the baby&amp;rsquo;s balance is supported by a parent or external object/apparatus.&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62787/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62787/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62787/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Any self-generated locomotion on a moving toy or baby furniture (e.g., a bicycle or bottomless car that the baby moves with their legs) counts as locomotion.&lt;/p&gt;

&lt;p&gt;Locomotion occurs when the entire body is displaced in any direction—forward, sideways, backward, in-place—space because the baby is taking a “step”.&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62775/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62775/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62775/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A baby takes a “step” by shifting weight from one foot/knee onto the other (i.e., weight must be shifting onto a swinging foot in the air to count as moving; if not, this is stationary).&lt;/p&gt;

&lt;p&gt;Onset of a “step” is when the whole foot/knee comes up off the ground.
A step can also happen if the foot doesn&amp;rsquo;t come off the ground, but the foot has to slide forward, backward or sideways.
Marching in place, jumping, and hopping also count as locomotion.
Offset is the frame when the baby takes the last step (with foot/knee) to pause in place (in the same posture such as walking to standing) or to transition to another stationary posture (e.g., upright walking to sitting).
A pause must last at least 0.5 s.&lt;/p&gt;

&lt;p&gt;Do not include any movement with foot/knee as part of a transition to another posture (e.g., sit to upright/walk).
The first walking/crawling step will be when the foot/knee moves forward in any direction.
The final step in the bout has to be a real walking/crawling step (i.e., it is not the last half step or little attempt-step that looks like a transition into the sit).
For example, if the baby transitions from sitting to crawling; the first step is after the transition ends and the last step is just before another transition begins.&lt;/p&gt;

&lt;p&gt;If the feet/knees/bum are outside the camera view, code the locomotion bout if you can see the body moving and/or can infer that the baby is moving.
If you are unsure as to whether the baby is moving or stationary (e.g., occlusion behind furniture or unclear video footage), then this bout should be coded as missing “.”, where the offset of the previous locomotion bout (just before the video occlusion or lack or view) should be set to the last frame where you can no longer see/infer the baby&amp;rsquo;s movement.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;f&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code &amp;lsquo;f&amp;rsquo; if the baby loses control over his/her body (i.e., balance) and cannot recover on his/her own before his/her body hits the ground.&lt;/p&gt;

&lt;p&gt;All falls count.
They can happen while upright, on/off furniture or other elevation, while sitting, or while engaged in locomotion.
Falls can happen while the mom is holding the baby&amp;rsquo;s hand or while the baby is holding onto furniture or another support.&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62747/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62747/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62747/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63330/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63330/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63330/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63336/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63336/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63336/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Onset is frame when baby first begins to lose balance and Offset when baby&amp;rsquo;s body (as defined below) hits the floor.&lt;/p&gt;

&lt;p&gt;From an upright or squatting position: a loss of balance results in the hands, knees, or a toy in the hands hitting the ground; baby&amp;rsquo;s bum hitting the ground; or head hitting the ground.&lt;/p&gt;

&lt;p&gt;From a crawling position: a loss of balance results in the face, head, chest, or side of torso hitting the ground.&lt;/p&gt;

&lt;p&gt;From a sitting position: a loss of balance results in the head, chest, side of torso, or back hitting the ground.&lt;/p&gt;

&lt;p&gt;A loss of balance must occur before any of the body parts hit the ground.
The baby must be out of his/her own control.
Sometimes babies will actively let themselves lose control (e.g., plopping down into a sit, where they let themselves fall down into a sitting position).
That is not a loss of balance but IS a loss of control and should count as a fall.&lt;/p&gt;

&lt;p&gt;If the baby loses balance, but catches him/herself before the above body parts hit the ground, do not count as a fall.&lt;/p&gt;

&lt;p&gt;Parent involved falls would only be coded as a fall if the parent catches the baby after the baby loses balance, effectively supporting the baby&amp;rsquo;s entire weight.
In this scenario, the baby would have fallen if not for parent rescue (i.e., the body part would have hit the ground). Parents must catch after the baby has begun to lose balance.
If the parent was already supporting the baby&amp;rsquo;s weight before a loss of balance, but baby&amp;rsquo;s body parts (e.g., hands, head, butt, etc.) do not touch the ground, then this is not a fall (it is supported walking).&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;m&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code &amp;rsquo;m&amp;rsquo; when the baby is being constrained and supported by the mother.
The baby&amp;rsquo;s feet are not on the ground and is being held in the air by the mother.
The mother&amp;rsquo;s arms are supplying support to the baby&amp;rsquo;s body by touching their torso.
Do not count mother constraint when the baby is just sitting on the mother&amp;rsquo;s lap.
During a mother constraint, the parent can be moving (carrying) or stationary (holding).&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62759/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62759/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62759/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62797/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62797/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62797/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Onset of hold is the last frame before the baby&amp;rsquo;s second foot (or bum if child was sitting, torso if child was laying down, second knee if crawling or knee walking) lifts up off the current surface and up into the air in mom&amp;rsquo;s arms.&lt;/p&gt;

&lt;p&gt;Offset of hold is when both feet touch the ground (or bum if mom places child in sitting, torso if mom places child laying down, both knees if mom places child in crawling or knee walking), and the baby starts supporting own weight in any posture.&lt;/p&gt;

&lt;p&gt;When mom is putting the baby back down, the onset for the immediate subsequent locomotion bout (if it happens) is when the second foot, hand, or knee touches the floor.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;d&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code &amp;rsquo;d&amp;rsquo; if the baby is constrained in a device that restricts movement (e.g., a highchair, stroller, carseat, etc.).
Device is not a couch, bed, or changing table unless there’s a strap, belt, or cord holding baby down.
Device can never be household furniture not intended for children. Wooden or plastic child chair is not a device without straps.&lt;/p&gt;

&lt;p&gt;Baby walker is not a device.
This would count as supported walking because that’s the whole point of a baby walker.
Jolly jumper counts as a constrained device even though the baby is moving or jumping around.&lt;/p&gt;

&lt;p&gt;Mom-constraint and device-constraint are likely to be continuous.
Mom-constraint ends as she puts baby into device.
Mom takes baby out of device is device-constraint transitioning into mom-constraint.&lt;/p&gt;

&lt;p&gt;Onset of constrained is when the baby&amp;rsquo;s butt first touches the restrictive device.&lt;/p&gt;

&lt;p&gt;Offset of constrained is when the butt leaves the device as the parent starts to take the baby out (usually by lifting them out).&lt;/p&gt;

&lt;h3 id=&#34;how-to-code&#34;&gt;How to Code&lt;/h3&gt;

&lt;p&gt;Set “JUMP-BACK-BY” key to 1 s.&lt;/p&gt;

&lt;p&gt;Enable cell highlighting.&lt;/p&gt;

&lt;p&gt;Watch in real time for the baby&amp;rsquo;s movement.&lt;/p&gt;

&lt;p&gt;Watch baby&amp;rsquo;s feet and knees.&lt;/p&gt;

&lt;p&gt;As soon as you see baby&amp;rsquo;s foot/knee lift up off of the ground; hit #5-STOP and then hit “JUMP-BACK-BY” to go back to the timestamp that is just before the lift.
Then JOG forward by hitting #3-JOGFORWARD until you reach the Onset of that cell.
If you go too far, you can JOG backward by hitting #1-JOGBACK. You will likely have to hit the JOG keys numerous times.
If you feel that you have either jumped too far back or went too far forward, hold the JOG keys to move in either direction a bit faster. Hit ENTER to create a new cell at this Onset.&lt;/p&gt;

&lt;p&gt;Now, watch in real time to see when the baby stops moving.
The Offset is when the baby stops moving for at least 0.5 s (the pause has to look and feel like an actual pause when you are watching in real time; don&amp;rsquo;t simply end a bout of locomotion because there was a 0.5-s pause, especially if it looks like the baby is about to take another step).
The first frame when the foot/knee stops moving or when the foot settles into its final position (sometimes infants stop their walking bout on their tip-toes) is the offset.
The same applies to sliding steps.&lt;/p&gt;

&lt;p&gt;To set the Offset, use the same rules for mechanics as with the onset. Hit #5-STOP and then hit “JUMP-BACK-BY” to go back to the timestamp that is just before the lift.
Then JOG forward by hitting #3-JOGFORWARD until you reach the Offset of that cell.
If you go to far, you can JOG backward by hitting #1-JOGBACK. You will likely have to hit the JOG keys numerous times.
If you feel that you have either jumped too far back or went too far forward, hold the JOG buttons to move in either direction a bit faster.&lt;/p&gt;

&lt;h2 id=&#34;momloc&#34;&gt;&lt;code&gt;momloc&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;loc_l-f&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;general-orientation-1&#34;&gt;General Orientation&lt;/h3&gt;

&lt;p&gt;This code captures the times that mom is engaged in locomotion or fell.&lt;/p&gt;

&lt;p&gt;Bouts of locomotion are scored as events, where the gray spaces between cells mean the mom is stationary.&lt;/p&gt;

&lt;p&gt;Coders are watching/tagging each of these events by marking onset/offset times for the duration of locomotion bouts.&lt;/p&gt;

&lt;p&gt;Coders are watching for steps with the feet, the knees, or the bum.&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62765/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62765/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62765/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62757/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62757/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62757/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Any other movements that are not initiated from these three body locations is considered to be a transition between postures and is subsumed by stationary, as it is not locomotion.&lt;/p&gt;

&lt;p&gt;Bouts that are coded as “.” means that mom is off camera or her legs are off camera, and coder cannot see or infer whether mom is stationary or moving.&lt;/p&gt;

&lt;h3 id=&#34;value-list-1&#34;&gt;Value List&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;l&lt;/code&gt; = locomotion&lt;/p&gt;

&lt;p&gt;&lt;code&gt;f&lt;/code&gt; = fall&lt;/p&gt;

&lt;p&gt;&lt;code&gt;.&lt;/code&gt; = when mother is off camera and coder cannot determine whether mom is moving or stationary&lt;/p&gt;

&lt;h3 id=&#34;operational-definitions-1&#34;&gt;Operational Definitions&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;l&amp;gt;&lt;/code&gt;
Code &amp;lsquo;l&amp;rsquo; when the mom is engaged in locomotion of any form (i.e., walking, scooting, knee-walking, crawling).&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62779/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62779/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62779/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62795/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62795/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62795/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62797/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62797/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62797/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re not sure whether the mom is moving or stationary (e.g., occlusion behind furniture or unclear video footage), then this is missing data and the offset of the locomotion bout should be set to the last frame where you can see mom.&lt;/p&gt;

&lt;p&gt;The subsequent cell (where you cannot see anything or make an inference about movement) should be coded as “.” until you can see mom again.&lt;/p&gt;

&lt;p&gt;However, if you can infer that mom is moving or stationary (i.e., head is bobbing, shadow of the leg moving is visible, etc.) then include it in the same bout of locomotion, following the rules for pauses above.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;f&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code &amp;lsquo;f&amp;rsquo; if the mom loses control over her body (i.e., balance) and cannot recover on her own before the body (bum, hands, torso) hits the ground.&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63360/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63360/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63360/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;All falls count. They can happen while upright, on/off furniture or other elevation, while sitting, or while engaged in locomotion.&lt;/p&gt;

&lt;p&gt;From an upright or squatting position: a loss of balance results in the hands, knees, or a toy in the hands hitting the ground.&lt;/p&gt;

&lt;h3 id=&#34;how-to-code-1&#34;&gt;How to Code&lt;/h3&gt;

&lt;p&gt;Set “JUMP-BACK-BY” key to 1 s.&lt;/p&gt;

&lt;p&gt;Enable cell highlighting on the controller.&lt;/p&gt;

&lt;p&gt;Watch in real time for the mom&amp;rsquo;s movement.&lt;/p&gt;

&lt;p&gt;Watch for the feet and knees.&lt;/p&gt;

&lt;p&gt;As soon as you see mom&amp;rsquo;s foot/knee lift up off of the ground; hit #5-STOP and then hit “JUMP-BACK-BY” to go back to the timestamp that is just before the lift.
Then JOG forward by hitting #3-JOGFORWARD until you reach the onset of that cell. If you go too far, you can JOG backward by hitting #1-JOGBACK.
If you feel that you have either jumped too far back or went too far forward, hold the JOG keys to move in either direction a bit faster.
Hit ENTER to create a new cell at this Onset.&lt;/p&gt;

&lt;p&gt;Now, watch in real time to see when the mom stops moving.
The Offset is when the mom stops moving for at least 0.5 s (the pause has to look and feel like an actual pause when you are watching in real time; don&amp;rsquo;t simply end a bout of locomotion because there was a 0.5-s pause, especially if it looks like the mom is about to take another step).
The first frame when the foot/knee stops moving or when the foot settles into its final position is the offset. The same applies to sliding steps.&lt;/p&gt;

&lt;p&gt;To set the Offset, use the same rules for mechanics as with the Onset.
Hit #5-STOP and then hit “JUMP-BACK-BY” to go back to the timestamp that is just before the lift.
Then JOG forward by hitting #3-JOGFORWARD until you reach the Offset of that cell.
If you go too far, you can JOG backward by hitting #1-JOGBACK.
You will likely have to hit the JOG keys numerous times.
If you feel that you have either jumped too far back or went too far forward, hold the JOG keys to move in either direction a bit faster.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/study/coding/objects/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0400</pubDate>
      
      <guid>/study/coding/objects/</guid>
      <description>

&lt;h1 id=&#34;coding-objects-objects-html&#34;&gt;Coding &lt;a href=&#34;objects.html&#34; target=&#34;_blank&#34;&gt;objects&lt;/a&gt;&lt;/h1&gt;

&lt;h2 id=&#34;babyobject&#34;&gt;&lt;code&gt;babyobject&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;obj&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;general-orientation&#34;&gt;General Orientation&lt;/h3&gt;

&lt;p&gt;This code captures the times that the baby is manually engaged with an object.&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62793/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62793/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62793/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62777/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62777/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62777/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Coders score only when object events occur, not when they don&amp;rsquo;t occur.
This is an event code, where gray spaces between cells mean that the baby is not engaged with an object.&lt;/p&gt;

&lt;h3 id=&#34;value-list&#34;&gt;Value List&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;o&lt;/code&gt; = object&lt;/p&gt;

&lt;p&gt;&lt;code&gt;.&lt;/code&gt; = when baby is off camera and coder cannot determine whether baby has an object in hand.&lt;/p&gt;

&lt;h3 id=&#34;operational-definitions&#34;&gt;Operational Definitions&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;obj&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Object = is defined as any manipulable, moveable item that may be detached and moved through space (e.g., toys, household items, and smaller moveable elements of larger objects like beads on busy box, doorknob).&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62763/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62763/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62763/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63765/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63765/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63765/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Objects may include large objects (i.e., a stroller, adult furniture, door, etc.) when baby moves them, thus, manually engaging with them.
If the object never moves (e.g., the baby has a hand on the stroller but does not displace it), then this is not coded as &amp;lsquo;o.&amp;rsquo;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63763/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63763/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63763/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The displacement rule is so that we can differentiate object engagement episodes from instances where baby is exploring a surface or resting hands on a surface for support.&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63767/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63767/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63767/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The infant does not have to be looking at the object for the event to count as an object engagement (e.g., baby is carrying object).&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62775/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62775/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62775/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Riding on toys with wheels does not count as object, but this will be coded in babyloc pass.&lt;/p&gt;

&lt;p&gt;Code &amp;lsquo;o&amp;rsquo; if the baby is engaged with an object by making contact with the item with hand(s) and/or moving the item in space (e.g., carrying, pushing on the floor, etc.)&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62783/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62783/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62783/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Onset is the frame when baby first causes the object to move while making contact with any part of the hand(s), not feet.
Contact could be from any part of the hand (fingers, palm, side of hand).
Movement could including lifting, holding, pressing, grasping, shaking, banging, or any other type of displacement event. DO NOT code onset, just when the hand touches the object if the object is not displaced (e.g., if they child touches a pillow but then 1 minute later actually grasps and moves it, code onset at the movement not when the hand touches the object).
Offset is the frame when baby is no longer in manual contact with an object for at least 3 s. OR when the baby is in manual contact but the object is no longer being displaced (displacement includes holding, lifting) for at least 3 s.
There is no minimum duration for baby to touch an object to be scored as &amp;lsquo;o,&amp;rsquo; but if infant is touching multiple objects, the offset of &amp;lsquo;o&amp;rsquo; object cell is when baby is no longer in manual contact with the last object contacted for 3+ s.
If the baby is in manual contact with an object in one hand and makes contact with another object with their second hand, count this as the same bout.&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62755/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62755/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62755/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;how-to-code&#34;&gt;How to Code&lt;/h3&gt;

&lt;p&gt;Set “JUMP-BACK-BY” key to 3 s.&lt;/p&gt;

&lt;p&gt;Enable cell highlighting.&lt;/p&gt;

&lt;p&gt;Watch in real time for the baby&amp;rsquo;s hand(s).
As soon as you see the hand(s) touch an object (as defined above), continue watching for a couple of seconds to see if the baby moves/manipulates the object.
Then, hit #4-SHUTTLEBACK to get to the onset of the cell.
The Onset is the first frame when the baby makes manual contact with the item.
Set this onset by hitting ENTER to set a new cell with that onset time.
Now, continue watching the object bout in real time and set the Offset when the baby breaks manual contact or stops moving object (e.g., stroller) for at least 3 s.
Once you&amp;rsquo;ve determined that the bout has ended, set the offset by hitting #5-STOP and then #4-SHUTTLEFORWARD or #6-SHUTTLEBACK to the last frame where the baby is no longer in manual contact with the item and/or when the baby is no longer moving it.
Then, hit #9-SETOFFSET.&lt;/p&gt;

&lt;p&gt;Continue watching in real time for the next object bout.
If the baby is holding an object while crawling or walking around, you can watch faster by SHUTTLING at 2x speed to find the end of the object engagement.&lt;/p&gt;

&lt;p&gt;To check whether a 3-s pause has occurred between object engagements, go to the offset of the previous object cell and watch until you reach the next instance of &amp;lsquo;o&amp;rsquo;.
Then, hit the &amp;lsquo;JUMP-BACK-BY&amp;rsquo; key and check to see if the previous cell lights up. If it does, then the two cells are &amp;lt;3 s apart and should be combined into one bout of &amp;lsquo;o&amp;rsquo;.&lt;/p&gt;

&lt;h2 id=&#34;momobject&#34;&gt;&lt;code&gt;momobject&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;obj&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;general-orientation-1&#34;&gt;General Orientation&lt;/h3&gt;

&lt;p&gt;This code captures the times that the mom is engaged with an object.
Coders score only when object events occur, not when they don&amp;rsquo;t occur.
This is an event code, where gray space in between cells means that the mom is not engaged with an object.&lt;/p&gt;

&lt;h3 id=&#34;value-list-1&#34;&gt;Value List&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;o&lt;/code&gt; = object.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;.&lt;/code&gt; = when mother is off camera and coder cannot determine whether she has an object in hand.&lt;/p&gt;

&lt;h3 id=&#34;operational-definitions-1&#34;&gt;Operational Definitions&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;obj&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Object = is defined as any manipulable, moveable item that may be detached and moved through space (e.g., toys, household items). Object can include parts of a stationary object (e.g., doorknob on door, clasp on drawer) that can be moved or manipulated.&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62767/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62767/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62767/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62781/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62781/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62781/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62791/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62791/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62791/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62781/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62781/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62781/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/62797/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/62797/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/62797/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Object can include large objects that mom may move (chairs).&lt;/p&gt;

&lt;p&gt;Code &amp;lsquo;o&amp;rsquo; if mom is engaged with an object by making contact with the item with her hand(s).
Onset is the frame when mom first makes contact with hands. Offset is the frame when mom is no longer in manual contact with an object for at least 3 s.
If the mom has multiple items in hand, the Onset of object is when a hand(s) touched the first object in the multiple-object-bout and the Offset is when the hand(s) release the last object.&lt;/p&gt;

&lt;p&gt;In cases of larger objects (i.e., a stroller, a box, a chair, a table, etc.), the object engagement begins when the object starts to move. If the large object never moves (e.g., the mom has a hand on the stroller but does not displace it), then this is not coded as &amp;lsquo;o&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63366/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63366/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63366/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If the mom is not in the camera view, code this with a &amp;lsquo;.&amp;rsquo; as missing data.&lt;/p&gt;

&lt;h3 id=&#34;how-to-code-1&#34;&gt;How to Code&lt;/h3&gt;

&lt;p&gt;Set “JUMP-BACK-BY” key to 3 s.&lt;/p&gt;

&lt;p&gt;Enable cell highlighting.&lt;/p&gt;

&lt;p&gt;Watch in real-time for the mom&amp;rsquo;s hand(s).
As soon as you see the hand(s) touch an object (as defined above), continue watching for a couple of seconds to see if the mom moves/manipulated the object (which would make this an instance of Object).
Then, hit #4-SHUTTLEBACK to get to the onset of the cell.
The Onset is the first frame when the mom makes manual contact with the item and moves it through space.
Set this onset by hitting ENTER to set a new cell with that onset time.
Now, continue watching the Object bout in real time and set the Offset when the mom breaks manual contact or stops moving the object for at least 3 s (i.e., Object bouts that are interrupted by gray space are more than 3 s apart.&lt;/p&gt;

&lt;p&gt;There is no necessary minimum duration for object engagement during the &amp;lsquo;o&amp;rsquo; bout to be coded as Object.
In other words, the mom can engage with an item or as little or as much time as they would like, however, the mom must make manual contact and move it through space to count.&lt;/p&gt;

&lt;p&gt;Once you&amp;rsquo;ve determined that the bout has ended, set the offset by hitting #5-STOP and then #4-SHUTTLEFORWARD or #6-SHUTTLEBACK to the last frame where the mom if no longer in manual contact with the item and/or when the mom is no longer moving it.
Then, hit #9-SETOFFSET.&lt;/p&gt;

&lt;p&gt;Continue watching in real time for the next object bout.
If the mom is walking or crawling with an object, watch at 2x speed.&lt;/p&gt;

&lt;p&gt;Do not agonize.
If the mom goes in and out of the camera view, but you know she is still holding the same object and has not put it down, code it in the same bout of &amp;lsquo;o&amp;rsquo;.
Do not mark the “.” for every few seconds she is out of frame.&lt;/p&gt;

&lt;p&gt;Code as Object event if mom&amp;rsquo;s back is to the camera, but you see her arms moving and she overtly appears to be manipulating something—even if you can&amp;rsquo;t see exactly what it is.&lt;/p&gt;

&lt;p&gt;Many times, onsets and offsets are coded when mom goes in and out of frame.
In these instances, hit the &lt;em&gt;0&lt;/em&gt; key to set a continuous cell, whose onset is 1-ms after the previous cell.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/study/coding/transcription/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0400</pubDate>
      
      <guid>/study/coding/transcription/</guid>
      <description>

&lt;h1 id=&#34;transcribing-transcription-html&#34;&gt;&lt;a href=&#34;transcription.html&#34; target=&#34;_blank&#34;&gt;Transcribing&lt;/a&gt;&lt;/h1&gt;

&lt;h2 id=&#34;transcribe&#34;&gt;&lt;code&gt;transcribe&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;source_m-b&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;content&amp;gt;&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;general-orientation&#34;&gt;General Orientation&lt;/h3&gt;

&lt;p&gt;The transcribe column is used to tag the onset of each utterance/vocalization by the mom and baby in a single pass.
Then based on the &lt;code&gt;&amp;lt;source&amp;gt;&lt;/code&gt; of the utterance/vocalization, the momspeech and babyvoc columns are automatically populated by a script.&lt;/p&gt;

&lt;p&gt;Utterance = a unit of speech separated by silence/pause, which can be a natural “period” as in end of a complete thought or sentence or a long pause (i.e., taking a breath).
Utterances are coded as events (cells) separated by gray where no utterances are spoken.
These are coded as events, where there is only one time that is tagged (onset), which is any time during the utterance.
We do not code strict onsets and offset for the event; a single time during the utterance is the time coded.&lt;/p&gt;

&lt;p&gt;Transcribe all of mothers&amp;rsquo; utterances even if they are not baby-directed.
But only transcribe communicative utterances; that is, there is no need to tag and transcribe non-speech, non-communicative sounds by the mother (e.g., making whistling noises, muttering to herself indistinguishably).&lt;/p&gt;

&lt;p&gt;Paralinguistic utterances/vocalizations (e.g., laughing, crying, sighing, screaming) by the mom should be typed out (e.g., “ah”).
Non-linguistic vocalizations by the baby are coded as “c” (a catch all for crying, laughing, screaming, grunting).
Linguistic babbling, vowels, consonants, and combinations of the above by the baby that are not words are coded as “b”.&lt;/p&gt;

&lt;h3 id=&#34;value-list&#34;&gt;Value List&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;source_m-b&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;m&lt;/code&gt; = mom&lt;/p&gt;

&lt;p&gt;&lt;code&gt;b&lt;/code&gt; = baby&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;content&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;If the content of the utterance can be heard clearly by the coder, then type transcript of each utterance in the cell.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;b&lt;/code&gt; = babbling, or vowel/consonant sound by the baby&lt;/p&gt;

&lt;p&gt;&lt;code&gt;c&lt;/code&gt; = crying, screaming, grunting, laughing sound by the baby&lt;/p&gt;

&lt;h3 id=&#34;operational-definitions&#34;&gt;Operational Definitions&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;source_m-b&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;m&amp;gt;&lt;/code&gt;: Code &amp;rsquo;m&amp;rsquo; if the mom is the source of the utterance. This code will be filled in automatically using quick keys.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;b&amp;gt;&lt;/code&gt;: Code &amp;lsquo;b&amp;rsquo; if the baby is the source of the utterance. This code will be filled in automatically using quick keys.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;content&amp;gt;&lt;/code&gt;
transcribe utterance
Type the complete utterance. Type everything in lower case, except for proper names (e.g., Mommy, I, Cheerios, Anna). Use apostrophes correctly for contractions and possessives (e.g., don&amp;rsquo;t, where&amp;rsquo;s, Daddy&amp;rsquo;s, Lily&amp;rsquo;s). Do not use “,” commas.&lt;/p&gt;

&lt;p&gt;Transcription: “snowmans dont drink coffee”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63400/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63400/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63400/download?inline=true&lt;/a&gt;
&lt;/br&gt;&lt;/p&gt;

&lt;p&gt;Transcription: “un caballo”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63406/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63406/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63406/download?inline=true&lt;/a&gt;
&lt;/br&gt;&lt;/p&gt;

&lt;p&gt;Transcription: “momma”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63404/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63404/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63404/download?inline=true&lt;/a&gt;
&lt;/br&gt;&lt;/p&gt;

&lt;p&gt;Transcription: “woof woof”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63414/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63414/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63414/download?inline=true&lt;/a&gt;
&lt;/br&gt;&lt;/p&gt;

&lt;p&gt;Put a question mark “?” at the end of any utterance that is a question.&lt;/p&gt;

&lt;p&gt;Transcription: “want cheerios?”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63408/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63408/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63408/download?inline=true&lt;/a&gt;
&lt;/br&gt;&lt;/p&gt;

&lt;p&gt;Individual letters (e.g., mom spells out zoo as “z” “o” “o”) need to be marked with an @ (at symbol) so that they&amp;rsquo;re not confused with actual words, for example z@ o@ o@.
Use existing rules for utterances to decide if each letter is it&amp;rsquo;s own utterance.&lt;/p&gt;

&lt;p&gt;Any utterance that is unintelligible or hard to decipher, code as “xxx”. This could be the full utterance: for example, the mom says multiple words but they are all unintelligible, so the entire code is “xxx”.
Or part of the utterance is intelligible, but part is not: for example, the mom says “give me” and what she says to give is unintelligible, so code “give me xxx”.&lt;/p&gt;

&lt;p&gt;Transcription: “xxx”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63412/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63412/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63412/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In case of language-functioning sounds by the mom or baby, these are typed out as words phonetically as specified below: Ahem (ready to speak), Ay (surprise), Huhuh (no), Hmm (thinking or questioning), Mmhm (yes), Sh (shush), Uhhuh (yes), Uhoh (blunder), uhuh (no), Yeah (yes), Whee (excitement), Whoah (surprise), Whoops (mistake)&lt;/p&gt;

&lt;p&gt;If you encounter a mouth sound that the mom makes, which is communicative but cannot be transcribed phonetically (e.g., lip sucking/kissing sound to call the baby over), write out the sound of the vocalization in brackets (e.g. [lip sucking/kissing]).&lt;/p&gt;

&lt;p&gt;Transcription: “[lip sucking/kissing]”
&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63398/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63398/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63398/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Only write out communicative sounds: for instance, if the mom whistles to get the baby&amp;rsquo;s attention write out [whistles], but if the mom is just whistling to herself as she cooks then do not tag as an utterance.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;b&amp;gt;&lt;/code&gt;
Code &amp;lsquo;b&amp;rsquo; if the baby is not saying a full language phrase or sentence. Could be babbling, by saying one or more consonant-vowel pairs. Or could be just a vowel.&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63338/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63338/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63338/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63340/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63340/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63340/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63342/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63342/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63342/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63344/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63344/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63344/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you are unsure if it was a language phrase that you can transcribe or was just a babble, then mark as unintelligible “xxx” and make a comment.
Either relisten or come back after getting more context later in the video.&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63410/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63410/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63410/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;c&amp;gt;&lt;/code&gt;
Code &amp;lsquo;c&amp;rsquo; if the baby is making a non-language-like vocalization. For instance, crying, screaming, laughing, grunting.
Any vocalization that is not a consonant-vowel babble or vowel alone.
These should be easy to distinguish from babbling, because they serve a different communicative function.&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63746/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63746/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63746/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63747/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63747/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63747/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/br&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
  &lt;source src=&#34;https://nyu.databrary.org/slot/14765/-/asset/63753/download?inline=true&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/br&gt;
&lt;a href=&#34;https://nyu.databrary.org/slot/14765/-/asset/63753/download?inline=true&#34; target=&#34;_blank&#34;&gt;https://nyu.databrary.org/slot/14765/-/asset/63753/download?inline=true&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;how-to-transcribe&#34;&gt;How to Transcribe&lt;/h3&gt;

&lt;p&gt;Set “Jump back by” on the Controller to 2 seconds.&lt;/p&gt;

&lt;p&gt;Transcribing is done in two iterative passes through a small section of the video (roughly 1-2 minutes).
The first part is tagging utterances for about 1-2 minutes (until a good break in activity is reached) and the second part is looping back over that same portion of the video to transcribe utterances.&lt;/p&gt;

&lt;h4 id=&#34;tagging-utterances&#34;&gt;Tagging Utterances&lt;/h4&gt;

&lt;p&gt;Turn on Quick Keys mode by hitting Shift-Cmnd-K (or selecting Spreadsheet&amp;gt;Enable Quick Keys from the menu bar).
You will see &lt;code&gt;&amp;lt;QUICK KEY MODE&amp;gt;&lt;/code&gt; in the spreadsheet window header.
This will enable a function that every time an alphanumeric key is pressed, a new point cell (onset=offset) is inserted at the current time in the data controller, and the alphanumeric key pressed will be inserted as the code of the first argument.&lt;/p&gt;

&lt;p&gt;Place your left index finger on the “m” key and your left ring finger on the “b” key.
The right fingers should be on pause and shuttle forward and back. Play the video at &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; speed (or &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt; speed if a fast exchange of utterances is happening).
Press the “m” or “b” key every time the mom or baby has an utterance, while you play the video back.
Insert cells as soon as you hear something. Be as alert and attentive as possible.&lt;/p&gt;

&lt;p&gt;If you think you hear an utterance, tag it.
It&amp;rsquo;s much better to be fast and insert extra cells, rather than judge yourself and have to go back later to fix the time or insert a cell for an utterance you missed. You can easily delete cells using shortcut keys.
You can also fix the &lt;code&gt;&amp;lt;source&amp;gt;&lt;/code&gt; code later if you hit the wrong key. Note, offsets are not coded.
Onsets are as close to the utterance onset as you possibly can get.
So optimize your attention and coding for speed of tagging.&lt;/p&gt;

&lt;p&gt;The best strategy is to have an unbroken playback session of 1-2 mins where you are just tagging utterances without stopping.
Stop playback once you&amp;rsquo;ve tagged 30-40 cells, 1-2 mins have elapsed, or you hit a good breaking point in an activity (e.g. baby moves onto playing with a new toy).
Try to stop a tagging utterances past as soon as you tag a new utterance, rather than playing further into silence of the video; that way you can jump to and pick up right where you left off at an utterance for the next tagging pass, instead of potentially re-playing the same part of the video.&lt;/p&gt;

&lt;p&gt;Now, turn off Quick Keys (Shift-Cmnd-K). Run the addtime_transcribe.rb script.
This will add 500 ms to the offset, which will help in highlighting in the next step.&lt;/p&gt;

&lt;h4 id=&#34;transcribe-utterances&#34;&gt;Transcribe Utterances&lt;/h4&gt;

&lt;p&gt;Turn on Highlight and Focus Mode by hitting Shift-Cmnd-F (or selecting Spreadsheet&amp;gt;Enable Highlight and Focus Mode from the menu bar).
This will highlight each cell as you loop back through the 1-2 mins you just tagged utterances in and put the focus of data entry (cursor) into the first uncoded argument in that cell (which will be &lt;code&gt;&amp;lt;content&amp;gt;&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;SCROLL or ARROW up to the first cell from the most recent utterance tagging done. Jump to that first cell (+ key) and then JUMP-BACK-BY 2 s (- key).
Playback the video at 1x speed. Listen to each utterance within the context of the ongoing stream of speech.
JUMP-BACK and re-listen as many times as needed until you are sure of the utterance. Once you are sure of the utterance, stop playback and transcribe the utterance or insert the appropriate code (for the baby).&lt;/p&gt;

&lt;p&gt;If you go past an utterance and missed transcribing it, hit the jump back key until you are right before it.
If you get lost in the transcription, JUMP BACK 2-3 cells (by arrowing or jump back key) before where you lost track of transcribing.
It&amp;rsquo;s much better to use the keyboard to navigate and loop back (jump back or arrow up or down) rather than mousing. (Note: you may need to mouse into the argument of the first cell in a section after tagging utterances).
If you mouse and jump around, you will get lost; stay in “looping” mode throughout transcription even if it means listening multiple times to a single section.&lt;/p&gt;

&lt;p&gt;If you find a cell for an utterance that was tagged by mistake (you thought there was an utterance but there wasn&amp;rsquo;t) then delete that cell.
JUMP-BACK-BY 2 s before the cell you deleted and confirm there was no utterance and that the next utterance is tagged at the correct time. (Note: you may need to mouse into a cell after deleting).&lt;/p&gt;

&lt;p&gt;If you need to change the onset of an utterance, ARROW into it (or let auto focus move you into it) and hit the 7 key to set onset to the current time.
Do not worry about setting or fixing the offset.&lt;/p&gt;

&lt;p&gt;If you missed tagging an utterance in the first part, find the time of the utterance onset while you are transcribing.
Hit ENTER and set the offset (same time as onset) using the 9 key.
Code “m” or “b” for &lt;code&gt;&amp;lt;source&amp;gt;&lt;/code&gt;, then tab into &lt;code&gt;&amp;lt;content&amp;gt;&lt;/code&gt; and transcribe.&lt;/p&gt;

&lt;p&gt;Turn off Highlight and Focus Mode. Save the file.
Now turn back on Quick Keys, jump to the onset of the last cell transcribed, and revert back to the coding strategy for tagging utterances.&lt;/p&gt;

&lt;h4 id=&#34;splitting-mom-and-baby-utterances&#34;&gt;Splitting Mom and Baby Utterances&lt;/h4&gt;

&lt;p&gt;It&amp;rsquo;s easier and faster to tag and transcribe mom and baby together in one pass.
But for later coding, we want mom speech and baby vocalizations to be in two separate columns.&lt;/p&gt;

&lt;p&gt;Run the &lt;code&gt;splitmombabytranscribe.rb&lt;/code&gt; script to pull mom and baby utterances into their appropriate columns.&lt;/p&gt;

&lt;p&gt;At this step, you can also run the &lt;code&gt;createmombabyutterancetype.rb&lt;/code&gt; script to insert the momutterancetype and babyutterancetype columns and insert cells for every tagged utterance.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/study/people/collaborators/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0400</pubDate>
      
      <guid>/study/people/collaborators/</guid>
      <description>

&lt;h2 id=&#34;collaborating-investigators&#34;&gt;Collaborating Investigators&lt;/h2&gt;

&lt;p&gt;The following provides information about which researchers are collecting data and which labs are coding and providing overall guidance on the project.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Last&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;First&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Institution&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Collection_role&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Adolph&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Karen&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;New York University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Amso&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Dima&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Brown University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Barr&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rachel&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Georgetown University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Berenbaum&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Sheri&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Penn State University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Bornstein&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Marc&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;SRCD&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Boudreau&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Jean-Paul&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Mount Alison University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Bradley&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Bob&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Arizona State University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Brandone&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Amanda&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lehigh University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Brooker&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rebecca&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Texas A&amp;amp;M&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Buss&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Kristin&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Penn State University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Casasola&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Marianella&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Cornell University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Chi&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Guangqing&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Penn State University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Claxton&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Laura&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Purdue University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Davis&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Elizabeth&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of California at Riverside&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;de Barbaro&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Kaya&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Texas at Austin&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Dusing&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Stacey&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Virginia Commonwealth University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Evans&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gary&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Cornell University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Fausey&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Caitlin&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Oregon&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Franchack&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;John&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of California at Riverside&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Frank&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Mike&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Stanford University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Frick&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Janet&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Georgia&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Gill&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Simone&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Boston University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Gilmore&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rick&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Penn State University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Goldin-Meadow&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Susan&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Chicago&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Goldstein&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Mike&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Cornell University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Haddad&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Jeff&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Purdue University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Halim&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;May Ling&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;California State University at Long Beach&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Hane&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Amie&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Williams College&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Hauck&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Janet&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Michigan State University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Heathcock&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Jill&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Ohio State University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Henderson&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Heather&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Waterloo&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Hirsh-Pasek&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Kathy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Temple University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Iverson&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Jana&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Pittsburgh&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Karasik&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lana&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;CUNY &amp;ndash; College of Staten Island&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Lee&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Do Kyeong&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;California State University at Fullerton&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Lee&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Mei-Hua&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Michigan State University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Legare&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Cristine&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Texas at Austin&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Lew-Williams&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Casey&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Princeton University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Libertus&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Klaus&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Pittsburgh&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;LoBue&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Vanessa&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Rutgers University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Lockman&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Jeff&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Tulane University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;MacWhinney&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Brian&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Carnegie Mellon University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Messinger&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Dan&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Miami&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Naigles&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Letitia&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Connecticut&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Namy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Laura&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Society for Research In Child Development&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Needham&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Amy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Vanderbilt University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Newcombe&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Nora&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Temple University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Oakes&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lisa&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of California at Davis&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Olson&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Kristina&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Washington&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Perez-Edgar&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Koraly&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Penn State University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Pomerantz&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Eva&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Illinois at Urbana-Champagne&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Prosser&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Laura&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Children&amp;rsquo;s Hospital of Philadelphia&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Rowe&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Meredith&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Harvard University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Schmuckler&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Mark&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Toronto Scarborough&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Sheya&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Adam&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Connecticut&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Soderstrom&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Melanie&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Manitoba&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Song&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Lulu&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Brooklyn College&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Tamis-LeMonda&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Catherine&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;New York University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Vishton&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Peter&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;College of William &amp;amp; Mary&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Walle&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Eric&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of California at Merced&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Not collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Wang&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Su-hua&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of California at Santa Cruz&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Warlaumont&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Anne&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of California at Los Angeles&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Yoshida&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Hanako&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Houston&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Yu&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Chen&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Indiana University&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Yurovsky&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Dan&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;University of Chicago&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Collecting&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Coding Manual</title>
      <link>/study/coding/coding_manual/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0400</pubDate>
      
      <guid>/study/coding/coding_manual/</guid>
      <description>&lt;!-- ```{r child = &#39;coding_setup.Rmarkdown&#39;} --&gt;

&lt;!-- ``` --&gt;

&lt;!-- ```{r child = &#39;transcription.Rmarkdown&#39;} --&gt;

&lt;!-- ``` --&gt;

&lt;!-- ```{r child = &#39;communication.Rmarkdown&#39;} --&gt;

&lt;!-- ``` --&gt;

&lt;!-- ```{r child = &#39;gesture.Rmarkdown&#39;} --&gt;

&lt;!-- ``` --&gt;

&lt;!-- ```{r child = &#39;locomotion.Rmarkdown&#39;} --&gt;

&lt;!-- ``` --&gt;

&lt;!-- ```{r child = &#39;objects.Rmarkdown&#39;} --&gt;

&lt;!-- ``` --&gt;

&lt;!-- ```{r child = &#39;emotion.Rmarkdown&#39;} --&gt;

&lt;!-- ``` --&gt;
</description>
    </item>
    
    <item>
      <title>PLAY Summit @ ICIS 2018 Philadelphia</title>
      <link>/talk/play-summit-2018/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 -0400</pubDate>
      
      <guid>/talk/play-summit-2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 -0400</pubDate>
      
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
